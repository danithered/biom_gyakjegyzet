# Folytonos eloszlások


## Folytonos eloszlások általános jellemzése

::: {.elmelet data-latex=""}

### Mi az, hogy folytonos?

A diszkrét eloszlásokkal ellentétben a folytonos eloszlások kategóriáit nem tudjuk nevesíteni (értékkészletük határozottan nem megszámlálható!), a valvált **minden** kiválasztott két értéke között tudunk találni végtelen számú más értéket. (Mondhatjuk azt is, hogy folytonos eloszlás esetén a kategóriák "egymásba csúsznak".) Skálájukat tekintve ezek az intervallum és arányskálás változók. Szóval ezek legalább valós számok ($X \in  \mathbb{R}$). Például ide tartoznak minden - nem kategorizáltan - mért hosszúság, idő vagy térfogat adatok. Gondoljunk bele, hogy ha emberek magasságát mérjük, akkor ha van egy 177.01 cm és egy 177.02 cm magas emberünk, attól még megvan a lehetősége annak, hogy találunk egy olyan embert, aki a kettő közözzi magasságú, például 177.014 cm magas. Persze el kell fogadnunk, hogy a mérési hibahatárok miatt nem tudunk végtelen tizedesjegy pontosságig mérni, de a lényeg az, hogy tudjuk, hogy elméletben mérhetnénk addig (vagyis inkább közelíthetően mérhetünk addig).  
Ebből adódik, hogy egy folytonos eloszlás esetén az elemi előfordulás valószínűsége 0 ($P(X=x) = 0$). Például annak a valószínűsége, hogy egy véletlenszerűen kiválasztott ember magassága pontosan 177.02 cm nulla, ugyanis, ha megnéznénk egy sokkal jobb mérési módszerrel, láthatnánk, hogy ez az ember valójában 172.02000000000000000001 cm magas, csak nem tudunk addig mérni.

:::

### Folytonos adatokkal való számolás

|x                        |n            | p        |
|:-----------------------:|:-----------:|:--------:|
| \(\displaystyle x_1 \)  | 1           | 0        |
| \(\displaystyle x_2 \)  | 1           | 0        |
| \(\displaystyle x_3 \)  | 1           | 0        |
| \(\displaystyle x_4 \)  | 1           | 0        |
| \(\displaystyle x_5 \)  | 1           | 0        |
| $\vdots$                | $\vdots$    | $\vdots$ |
| \(\displaystyle x_N \)  | 1           | 0        |


Folytonos eloszlás esetén minden megfigyelés legfeljebb csak egyszer fog előkerülni, így nincs értelme számolni az elemi előfordulások számát, sem a gyakoriságát nézni (előbbi mindig 0 vagy 1, utóbbi mindig 0).  
Ugyan azt nem lehet megmondani, hogy egy valvált **pontosan** megegyezik-e egy adott értékkel ($X ?= x$), azt meg tudjuk mondani, hogy egy adott értéknél kisebb ($X ?\le x$) vagy nagyobb-e ($X ?\ge x$). Így el tudjuk azt is dönteni, hogy bele tartozik-e egy adott intervallumba ($X ?\in [a;b]$). 
Régebben, mikor még nem állt elég számítási kapacitás rendelkezésre, a könnyebb számolás érdekében kategorizálni szokták a folytonos változókat, azaz meg szoktak húzni $\delta x$ szélességű intervallumokat és ebbe szokták belerakni a folytonos változókat (megszámolják hány vátozó esik bele az adott intervallumokba - $n$, illetve kiszámolják ezek gyakoriságát - $p$). Ezt az eljárást hívjuk "diszkretizálás"-nak. Egy ilyet mutat meg a lenti táblázat.


|x intervallum                                                  |n            | p                                                      |
|:-------------------------------------------------------------:|:-----------:|:------------------------------------------------------:|
| \(\displaystyle [x_0; x_0 + \delta x] \)                      | $n_1$         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + \delta x; x_0 + 2 \delta x)] \)        | $n_2$         | \(\displaystyle  p_1 = {n_2} / {\sum n_i} = n_2 / N \) |
| \(\displaystyle [x_0 + 2 \delta x; x_0 + 3 \delta x)] \)      | $n_3$         | \(\displaystyle  p_1 = {n_3} / {\sum n_i} = n_3 / N \) |
| \(\displaystyle [x_0 + 3 \delta x; x_0 + 4 \delta x)] \)      | $n_4$         | \(\displaystyle  p_1 = {n_4} / {\sum n_i} = n_4 / N \) |
| $\vdots$                                                      | $\vdots$    | $\vdots$                                               |
| \(\displaystyle [x_0 + (m-1) \delta x; x_0 + m \delta x)] \)  | $n_m$         | \(\displaystyle  p_1 = {n_m} / {\sum n_i} = n_m / N \) |

Ennél bonyolultabb, ha a $\delta x$ értékek kategóriánként eltérnek, azaz a diszkrét csoportokat más-más szélességű intervallumok alkotják. A diszkretizált adatokkal való számolást nem tanuljuk a kurzus során (mivel a XXI. században az nem adna releváns gyakorlati tudást), de a diszkretizálás fogalmával tisztában kell lenni.  


Fontos megkülönböztetni, hogy adatokról vagy eloszlásokról beszélünk-e! A folytonos eloszlások elméleti fogalmak, azok a valós adatoktól függetlenek! Folytonos eloszlásokkal tudjuk **jellemezni** a valós adatokat, de azok nem egyeznek meg, ne keverjük össze a fogalmakat!  

### PDF és CDF

::: {.plusinfo data-latex=""}

A diszkrét eloszlásokkal ellentétben a folytonos tömegfüggvényeket nem szoktuk valószínűségi tömegfüggvénnyel (PMF) jellemezni (hisz annak értéke mindig 0 lenne), cserébe **sűrűségfüggvénnyel** (PDF = **P**robability **D**ensity **F**unction) jellemezzük. A sűrűségfüggvény a valvált értékeihez olyan értékeket rendel, ami körülbelül azt mutatja meg, hogy mekkora a relatív esélye annak, hogy a valvált adott értékéhez közeli értéket húzunk ki. (Ne felejtsük el, annak az esélye, hogy pontosan egy adott számot húzunk ki 0!) Más megközelítéssel, mekkora az esélye annak, hogy egy random minta átlaga megegyezzen a valvált adott értékével más random mintákhoz képest.  
A sűrűségfüggvény szemléletes megértésében segít, ha elképzeljük, hogy a folytonos valváltot diszkretizáljuk és megnézzünk annak PMF-ét. Ha nagy kategóriákat veszünk ($\delta x$ nagy, azaz a kategóriák száma $m$ kicsi) és összehasolítjuk az eredeti folytonos eloszlás PDF-ével, azt látjuk, hogy bár karakterisztikájában a két függvény hasonlít, azért vannak erős eltérések. Ha azonban kisebb kategóriákat veszünk ($\delta x$ kisebb, azaz a kategóriák száma $m$ nagyobb), a két függvény kezd hasonlítani egymásra. Könnyű elképzelni, hogy ahogy $\delta x$ egyre kisebb lesz, azaz tart a nullához (a valvált egyre inkább kezdi elveszteni diszkrét jellegét), a két függvény kezd egyre jobban hasonlítani egymáshoz. Azonban, míg a diszkrét függvény esetén az y-tengely a valószínűséget mutatta, a folytonos esetén a sűrűséget.  

:::

```{r , fig.cap="Normális (folytonos) eloszlás közelítése binomiális (diszkrét) eloszlással. Az első oszlopban a piros vonalak a normális eloszlás valválthoz tartozó sűrűségfüggvényét (PDF) rajzolják ki, míg a szürke oszlopok a binomiális eloszláshoz tartozó tömegfüggvényét (PMF). A második oszlopban a normális eloszláshoz (piros vonal) és a binomiális eloszláshoz (szürke oszlopok) tartozó eloszlásfüggvények (CDF) vannak. Fentről lefelé soronként nő a binomiális eloszlás mintamérete, azaz a diszkretizálás felbontása.", echo=F}
prob=0.5
size=3
ra=c(round((size*prob -3*sqrt(size*prob*(1-prob)))):round(size*prob +3*sqrt(size*prob*(1-prob))))
pl <- list() 
pl[[1]]<-	ggplot(data.frame(x = ra, y=dbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red") +
		ylab("f(x)") +
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

pl[[2]]<- ggplot(data.frame(x = ra, y=pbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		ylab("f(x)") +
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

size=4
ra=c(round((size*prob -3*sqrt(size*prob*(1-prob)))):round(size*prob +3*sqrt(size*prob*(1-prob))))
pl[[3]]<- ggplot(data.frame(x = ra, y=dbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

pl[[4]]<- ggplot(data.frame(x = ra, y=pbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())


size=10
ra=c(round((size*prob -3*sqrt(size*prob*(1-prob)))):round(size*prob +3*sqrt(size*prob*(1-prob))))
pl[[5]]<- ggplot(data.frame(x = ra, y=dbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

pl[[6]]<- ggplot(data.frame(x = ra, y=pbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())


size=50
ra=c(round((size*prob -3*sqrt(size*prob*(1-prob)))):round(size*prob +3*sqrt(size*prob*(1-prob))))
pl[[7]]<- ggplot(data.frame(x = ra, y=dbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

pl[[8]]<- ggplot(data.frame(x = ra, y=pbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

size=150
ra=c(round((size*prob -3*sqrt(size*prob*(1-prob)))):round(size*prob +3*sqrt(size*prob*(1-prob))))
pl[[9]]<- ggplot(data.frame(x = ra, y=dbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

pl[[10]]<- ggplot(data.frame(x = ra, y=pbinom(ra, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
		ylab("f(x)") +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

#grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10, ncol=2)
col.titles <- c("PMF/PDF", "CDF")
ncol=length(col.titles)
grid.arrange(
  grobs=lapply(1:ncol, function(i) {
    arrangeGrob(grobs=pl[0:(length(pl)/ncol-1)*ncol +i], top=col.titles, ncol=1)
  }
), ncol=ncol)


```

Míg folytonos eloszlás esetén nincs értelme elemi valószínűségeket számolni, intervallumok valószínűségét tudjuk és érdemes kiszámolni. Ezt a sűrűségfüggvényből úgy tudjuk kiszámolni, hogy megnézzük a valvált kijelölt intervallumához tartozó függvény alatti terület nagyságát, azaz az integrálját. Az eloszlásfüggvény ($F(X)$) tehát valójában a sűrűségfüggvény ($f(X)$) integrálja.

$$F(X,x)=\int_{- \infty}^{x} f(X) \, dx =P(X \le x)$$

A sűrűségfüggvény határozott intergálja megmutatja, hogy egy véletleszerűen húzott valvált mekkora valószínűséggel vesz fel $a$ és $b$ közötti értéket.

$$\int_A^B f(X) \, dx= P(a \le X \le b)$$


Ha a valvált teljes intervallumát nézzük (mínusz végtelentől plusz végtelenig), azt tudjuk, hogy az ahhoz tartozó valószínűség 1, azaz a sűrűségfüggvény határozatlan integrálja 1. (Vagyis a sűrűségfüggvény alatti terület nagysága = 1.)

$$\int_{- \infty }^{+ \infty} f(X) \, dx = 1$$

### Valószínűségek számítása

Ha meg akarjuk nézni, hogy egy valvált mekkora valószínűséggel vesz fel egy adott $a$ értéknél kisebbet, akkor így számoljuk ki:

$$P(X \le a) =F(a) = \int_{- \infty}^{a} f(X) \, dx$$

Ne felejtsük el, hogy mivel az elemi előfordulás valószínűsége 0 ($P(X=a)=0$), ezért $P(X \le a) = P(X < a)$!

Előbbi valószínűséget a sűrűségfüggvényről úgy lehet "leolvasni", hogy x tengelyen kikeressük $a$ értékét (piros pont az ábrán) és megnézzük, hogy mekkora az $a$ pont előtt a függvény alatti (az ábrán zöld) terület nagysága. Természetesen ezt ténylegesen leolvasni nem tudjuk. A CDF-ről viszont igen, csak meg nézni, hogy a valvált adott értékéhez milyen érték tartozik az y-tengelyen (zöld pötty). 

```{r plnorm, echo=F, fig.cap="Folytonos (normális) eloszlás PDF és CDF"}
a=2
plot1 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pnorm(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=pnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pnorm(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)

```

Azonban, ha arra vagyunk kíváncsiak, hogy milyen valószínűséggel vesz fel egy adott $a$ értéknél nagyobb értéket, akkor ki kell használnunk, hogy 

$$\int_{- \infty}^{+ \infty} f(X) \, dx=1$$

azaz, hogy a teljes eseménytér valószínűsége (a görbe alatti teljes terület) 1. Tehát 1-ből ha kivonjuk annak a térrésznek a nagyságát, ami az adott térrésznél kisebb (ábrán a zöld terület) - vagyis annak a valószínéségét, hogy $a$-t vagy kisebbet húzunk, akkor megkapjuk annak a valószínűségét, hogy $a$-nál nagyobbat húzunk (ábrán a görbe alatti nem színezett terület).

$$P(X \ge a) = 1-P(X \le a) = 1- \int_{- \infty}^a f(X) \,dx$$

Ha blokkokra / intervallumokra vagyunk kíváncsiak, akkor is úgy járunk el, hogy kivonjuk egymásból a valószínűségeket ("területeket"). Ha pl. arra vagyunk kíváncsiak, hogy mekkora eséllyel vesz fel egy valvált $a$ és $b$ közötti értéket először kiszámoljuk $P(X \le b)$-t (Step 1 zöld rész), majd kivonjuk belőle azt a részt, ami nem kell (Step 2 piros rész), vagyis $P(X \le a)$-t és ami marad az a végeredmény (Result zöld rész). 

```{r , echo=F, fig.height=2, fig.cap="Legalább a és legfeljebb b kiszámolása"}

a=1
b=2
plot1 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,b)
                , geom = "area"
                , fill="lightgreen"
                ) +
	#geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	#geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	#annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	#annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Step 1")

plot2 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,b)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="coral"
                ) +
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Step 2")

plot3 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(a,b)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Result")



	

grid.arrange(plot1, plot2, plot3, ncol=3)
```

$$P(a \le X \le b) = P(X \le b) - P(X \le a)= \int_a^b f(X) \, dx = \int_{- \infty}^b f(X) \, dx - \int_{- \infty}^a f(X) \, dx$$
Ha annak a valószínűségét akarjuk kiszámolni, hogy egy valvált értéke **nem** esik $a$ és $b$ közé, azaz $a$-nál kisebb vagy $b$-nél nagyobb ( . ábra), az előző részben kiszámolt valószínűséget kivonjuk 1-ből.

```{r , echo=F, fig.cap="Nem a és b között"}
a=1
b=2
ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(b,3)
                , geom = "area"
                , fill="lightgreen"
                ) +
	#geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	#geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	#annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	#annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)")
```

$$P( X \le a ~ | ~ X \ge b) = 1-P(a \le X \le b) = 1- (P(X \le b) - P(X \le a)) = 1- P(X \le b) + P(X \le a)) $$

$$\int_{-\infty}^a f(X) \, dx + \int_{b}^{+\infty} f(X) \, dx = 1- \left ( \int_{- \infty}^b f(X) \, dx - \int_{- \infty}^a f(X) \, dx \right ) = 1- \int_{- \infty}^b f(X) \, dx + \int_{- \infty}^a f(X) \, dx$$

Néha visszafelé is számolni kell: adott egy valószínűségi érték és ehhez kell kiszámolni, hogy a valvált melyik értéktartományához (intervallum alsó-, felső határának kiszámítása) tartozik. Ezt a reverz CDF-el tudjuk kiszámolni.

**R**-ben a CDF-et és a reverzét a `p...()` és `q...()` formájú függvényekkel fogjuk elérni.

$$
\begin{gathered}
valvált \rightarrow \mathbf{p} \rightarrow P(X \le x) \\
P(X \le x) \rightarrow \mathbf{q} \rightarrow valvált 
\end{gathered}
$$

## Egyenletes eloszlás

### Általános leírás

::: {.elmelet data-latex=""}

Az egyenletes eloszlás az, amikor minden érték egyforma valószínűséggel fordul elő egy adott intervallumban. Ez leggyakrabban mint elméleti feltevés fordul elő.  

:::

Az egyenletes eloszlás két paramétere a *minimum* és *maximum* érték. A sűrűségfüggvény képlete:

$$f(X) = \frac {1}{max-min} \text{, ha } a \le X \le b$$

Az eloszlásfüggvény pedig

$$F(X)=\frac{X-min}{max-min}$$

### Várható érték, variancia

Az eloszlás várható értéke a valvált minimuma és maximuma által jelzett intervallum közepe:

$$E(X)= \frac { max + min }{2}$$

Az eloszlás varianciája:

$$SD^2(X)=\frac {(max-min)^2}{12}$$



### Valószínűségek számítása


```{r unif, fig.cap="Egyenletes eloszlás PDF és CDF\\label{discrunif}", echo=FALSE}
a=0.4

plot1 <- ggplot() +
	stat_function(fun = dunif 
								, xlim = c(-1,a)
								, geom = "area"
								, fill="lightgreen"
	) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dunif(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dunif(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dunif, xlim=c(-1,2)) +
	scale_x_continuous(labels=c("min", "max", "a"), breaks=c(0, 1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dunif(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dunif(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")


plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= punif(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,punif(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=punif, xlim=c(-1,2)) +
	scale_x_continuous(labels=c("min", "max", "a"), breaks=c(0,1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = punif(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = punif(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```

A . ábrán látható a folytonos egyenletes eloszlás tömegfüggvénye és eloszlásfüggvénye. A PDF-en látható, hogy a minimum és maximum között egyenlő valószínűséggel húzhatunk ki számokat, míg azokon kívül nem húzhatunk ki.   

Ha ki szeretnénk számolni, hogy mennyi az esélye, hogy $a$ -nál kisebb értéket vesz fel egy random kihúzott szám, leolvashatjuk a grafikonokról: A PMF-en kikeressük az x-tengelyen $a$-t (piros pötty), majd leolvassuk mekkora a területe a görbe alatti terület azon részének, ami $a$ előtt van. Természetesen ezt a gyakorlatban nem tudjuk (és nem érdemes) megcsinálni. Szerencsére a CDF -ről le tudjuk olvasni: az $a$-hoz tartozó függvényértéket kikeressük az y-tengelyen (zöld pötty). De ki is számolhatjuk kézzel: 

$$F(a)=\frac{a-min}{max-min}$$

, vagy **R**-ben:

```{r}
min=5
max=10
a=7
punif(a, min, max)
```

Ha ugyanebből az eloszlából meg szeretnénk tudni, hogy a "nagyobbik" harmad honnan kezdődik, akkor a reverz eloszlásfügvényt használjuk.

```{r}
qunif(1-1/3, min, max)
```

Azért $1-1/3$ -ra számoltuk, mert a harmadik harmadra voltunk kíváncsiak.

## Normális eloszlás

### Általános leírás

::: {.elmelet data-latex=""}

A normális eloszlás (Gauss eloszlás, haranggörbe) a természetben leggyakrabban előforduló eloszlás. Ennek okairól lásd az előadás centrális határeloszlás tételről szóló részét!  
Az eloszlást valahogy úgy kell elképzelni, hogy van egy érték ($\mu$ - várható érték) ami jelöli, hogy az értékek leggyakrabban arrafelé, annak közvetlen környezetében vannak, ettől az értéktől távol meg ugyan előfordulhatnak értékek, de csak nagyon ritkán. Ezért hívják haranggörbének is, mert harang alakú. Ez az eloszlás a várható értékére **szimmetrikus** és csak 1 csúcsa van!
Gondoljuk például az emberek magasságára! Ugyan mi látjuk a különbségeket egymás közt, de a többség körülbelül egyforma magas. Ha pedig találkozunk egy 0.5 méter vagy egy 2,3 m méter magas emberrel, akkor csodálkozunk, mert ugyan előfordulhat, de nagyon-nagyon ritkán.  

:::

A normális eloszlás paraméterei:

* $\mu$: **várható érték** (merre várhatóak az értékek)
* $\sigma$: **szórás** (mennyire szóródottak az értékek a várható értékhez képest)

### Standard normális eloszlás


Ha több normális eloszlást össze akarunk hasonlítani, kell lennie egy alapnak, amihez minden mást viszonyítunk. Ez lesz a standard. Definíció szerint a standard normális eloszlás várható értéke 0 ($\mu=0$), szórása 1 ($\sigma=1$). Sok más eloszlásnak, így sok statisztikai módszernek/próbának ez lesz az alapja, így érdemes az eloszlás főbb jellegzetességeit eszünkbe vésni!

::: {.plusinfo data-latex=""}

A standard normális eloszlás ($\Phi(x)$ - görög fí) képletét akár magunknak is levezethetjük. Először is vegyük a főbb jellegzetességeket: 0-ra szimmetrikus, valahogyan "görbülő" függvény. Erre a legegyszerűbb példa a négyzet függvény:

$$f(x) = x^2$$
```{r}
curve(x^2, xlim=c(-2,2))
```

Ezt azonban meg kéne fordítani...


$$f(x) = -x^2$$

```{r}
curve(-x^2, xlim=c(-2,2))
```

Máris jobb, azonban a görbülete nem jó - nekünk konkáv függvény kellene, ráadásul negatív az egész (nem szabadna sosem elérnie a 0-t). A legegyszerűbb függvény, ami az előző két feltételt teljesíti, az a az exponenciális függvény ($e^x$). Emeljük az előző függvényünket exponenciálisra!

$$f(x) = e^{-x^2}$$

```{r}
curve(exp(-x^2), xlim=c(-2,2))
```

Máris sokkal jobb! Már csak pár probléma van: egy kicsit túl "szűk", valamint a függvény görbéje alatti terület nem 1. Ahhoz, hogy a szórása egység méretű ($\sigma=1$) legyen a hatványkitevőt le kell osztani 2-vel:


$$f(x) = e^{-x^2 \frac{1}{2}}$$

```{r}
curve(exp(-x^2/2), xlim=c(-2,2))
curve(exp(-x^2), xlim=c(-2,2), add=T, col="grey", lty=2) #elozo gorbe
```

Kell egy skálázó faktor ($a$), hogy a függvény integrálja 1 legyen:

$$\int a \cdot e^{-x^2 \frac{1}{2}} ~dx=1$$

Ezt úgy kapjuk meg legegyszerűbben, hogy a függvényt leosztjuk az integráljával (ne felejtsük el, hogy $a$ konstans lesz!), mert ugye $x/x=1$. Az integrál:

$$\int_{-\infty}^{+\infty} e^{-x^2 \frac{1}{2}} ~dx= \sqrt {2 \pi}$$

Szóval $a$ helyére beírjuk az integrál értékét és kész is a standard normál eloszlás sűrűségfüggvénye:

$$\Phi(x) = \frac{1}{\sqrt{2 \pi}} e^{-x^2 \frac{1}{2}}$$


```{r}
curve(exp(-x^2/2)/sqrt(2*pi), xlim=c(-2,2))
```

Egy ábrán lásd: . ábra.

```{r , fig.cap="Standard normális eloszlás sűrűségfüggvénye"}
cols <- brewer.pal(4, "Set1")
curve(exp(-x^2/2)/sqrt(2*pi), xlim=c(-2,2), ylim=c(-1.5,1), lwd=1.5, ylab="f(x)", las=1)
abline(h=0, col="grey")
abline(v=0, col="grey")
curve(exp(-x^2/2), add=T, col=cols[1], lty=2, lwd=1.5)
curve(exp(-x^2), add=T, col=cols[2], lty=2, lwd=1.5)
curve(-x^2, add=T, col=cols[3], lty=2, lwd=1.5)
curve(x^2, col=cols[4], add=T, lty=2, lwd=1.5)
legend("bottom", 
			 legend=c(expression(x^2), 
			 				 expression(-x^2),
			 				 expression(e^{-x^2}),
			 				 expression(e^{-1/2*x^2} ),
			 				 expression(1/sqrt(2* pi )*e^{-1/2*x^2})),
			 lty=c(2,2,2,2,1),
			 col=c(rev(cols), "black"),
			 lwd=1.5, bg="white"
)
```
:::

### Általános normális eloszlás

::: {.plusinfo data-latex=""}

A standard normális eloszláshoz képest annyi a különbség, hogy az x-tengelyen eltoljuk a függvényt ($\mu$-t megváltoztatjuk 0-ról) és megváltoztatjuk a szórását. Az x-tengelyen való eltoláshoz a képletben $x$ -et megváltoztatjuk $x+\mu$ -re. A szórás megváltoztatásához pedig (standard norm esetén $\sigma=1$) x-et leosztjuk $\sigma$-val. Mivel ezt megtettük, így az első tag is változik $1/(\sigma \sqrt {2 \pi})$ -re:

:::

$$f(x) = \frac{1}{\sigma\sqrt{2 \pi}} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2 }$$

Így kaptunk egy általános sűrűségfüggvényt, aminek mi állíthatjuk be a várható értékét és szórását.  
Az eloszlásfüggvény pedig ennek integrálja:

$$F(x)=\int_{-\infty}^x f(x) = \int_{-\infty}^x\frac{1}{\sigma\sqrt{2 \pi}} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2 }$$

### Konvertálás standardre és vissza (z-transzformáció)

Előfordul, hogy egy normális eloszlást standard normális eloszlásra kell transzformálni. Ezt **z-transzformáció**nak hívjuk. 
Ekkor először is, "eltoljuk" a normális eloszlást az x-tengelyen úgy, hogy várható értéke nulla legyen. Ezt úgy tudjuk megcsinálni, hogy kivonjuk az értékeiből a normális eloszlás várható értékét (ha nem ismerjük, akkor a minta átlagát). Az így kapott $x-\sigma$ eloszlásnak már csak a szórását kell standardizálni, ezt pedig úgy tudjuk, hogy leosztjuk az átalakított értékeinket az eloszlás (vagy minta) szórásával ($\sigma$). Meg is kaptuk az új, standardizált eloszlásunk értékeit ($z$)!

```{r , fig.cap="Z-transzformáció. Egy általános normális eloszlás (piros vonal) átalakítása standard normál eloszlássá (fekete vonal). A pontozott vonalak jelzik a két eredeti eloszlás várható értékét, a nyíl pedig az eltolás írányát. Szaggatott halványpiros vonal jelzi az eltolt várható értékű normális eloszlást.", echo=T}
m <- 5
s <- 2

par(lwd=2)
curve(dnorm, xlim=c(-4,10), ylab="f(x)", las=1)
curve(dnorm(x, mean=m, sd=s), add=T, col="red")
curve( dnorm(x, sd=s) , add=T, col="coral", lty=2)
legend("topright", 
			 legend=c( expression(Phi), "x" , expression( x - bar(x) ) ),
			 lty=c(1,1,2), lwd=1.5, col=c("black", "red", "coral" )  )
abline(v=m, col="coral", lty=3, lwd=1)
abline(v=0, col="grey", lty=3, lwd=1)
arrows(m, 0.3, 0, length=0.1, col="lightblue", lwd=1)
```

$$z=\frac{x-\mu}{\sigma}$$

$$z= \frac{x- \bar x}{SD_x}$$

Például van egy adatsorunk $x=\{9.9; 8.3; 10.3; 14.3; 10.8; 9.8; 4.8; 9.4; 8.6; 9.5\}$, amit szeretnénk standard normál eloszlásúvá alakítani. Kiszámoljuk, hogy ennek átlaga $\bar x = 9.6$, szórása $SD_x=2.4$. Ekkor kiszámítjuk a standardizált értékeket a $z=(x-9.6)/2.4$ képlettel, vagyis $z_1=(9.9-9.6)/2.4=0.14$, $z_2=(8.3-9.6)/2.4=-0.54$, stb. Ezt **R**-ben:

```{r}
x <- c(9.9, 8.3, 10.3, 14.3, 10.8, 9.8, 4.8, 9.4, 8.6, 9.5)
atlag= mean(x)
szoras=sd(x)

(x-atlag)/szoras # z ertekek
```

Azonban megjelenik egy munkatársunk aki megmondja, hogy ismeri az eredeti populációnk várható értékét ($\mu=10$) és szórását ($\sigma=2$). Ekkor, mivel ez a pontosabb érték ezzel kell számolnunk:

```{r}
x <- c(9.9, 8.3, 10.3, 14.3, 10.8, 9.8, 4.8, 9.4, 8.6, 9.5)
mu = 10
sigma = 2

(x-mu)/sigma # z ertekek
```

Van olyan eset is, amikor az eredményeket $z$-értékben, vagyis standard normális eloszlás értékeiként kapjuk meg ($z$), nekünk meg át kell alakítani olyan értékekre, amiket tudunk értelmezni a mi adatainkon ($x$). Ezt az előző egyenlet átrendezésével tudjuk megoldani:

$$x=\mu + z \cdot \sigma$$

$$x=\bar x + z \cdot SD_x$$

Tehát, ha megkapjuk, hogy egy standard normális eloszlás egyik értéke $z=0.34$, de a mi vizsgált populációnk várható értéke $\mu=214$ és szórása $\sigma=24.1$, akkor, hogy ezt a z-értéket a mi populációnkon tudjuk értelmezni így számoljuk ki: $214+0.34*24.1 = 222.19$

### Valószínűségek számítása

```{r norm0, echo=FALSE, fig.cap="Normális eloszlás PDF és CDF"}
a=2
plot1 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pnorm(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=pnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pnorm(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```

A . ábrán látható a normális eloszlás sűrűségfüggvénye és eloszlásfüggvénye.  
Az eloszlásfüggvényt a `pnorm(..., mean, sd)` függvénnyel lehet kiszámítani, ahol a `mean` a várható érték, azaz $\mu$, az `sd` pedig az eloszlás szórása, tehát $\sigma$. Az eloszlásfüggvény inverzét a `qnorm(..., mean, sd)` függvénnyel tudjuk kiszámítani. Ha elfelejtenénk, hogy a függvény paraméterei mit jelentenek futtassuk le a `?pnorm` parancsot az **R**-ben és a helpből kikereshetjük.

Számoljuk ki mekkora az esélye egy standard normális eloszlás ($\sigma=1$, $\mu=0$) esetén, hogy $X \le 2$! 
Ezt leolvashatjuk az ábráról is: kikerssük a CDF-en a 2-t az x-tengelyen (piros pötty), majd megnézzük milyen y-tengely értéket vesz fel (zöld pötty).  

::: {.plusinfo data-latex=""}

Az ilyen számolásokat egyébként régebben a z-táblázatból számítottuk ki. Ehhez először is a keresett értéket z-transzformációval át kell alakítani standard normális eloszlás értékévé (jelen esetben ez megvan), majd az oszlopok és sor fejlécekből kikeressük a $z$ értéket (egyik fejléc tartalmazza általában egy tizedesjegyig a számokat, a másik a 2. tizedesjegyet tartalmazza), majd a megfelelő sor és oszlop metszetében lévő értéket leolvassuk. 

:::

Azért **R**-ben ez jóval egyszerűbb:

```{r}
pnorm(2, mean=0, sd=1)
```

Ha arra vagyunk kíváncsiak, hogy mekkora az értékek középső 25% -át tartlamazó intervallum ( . ábrán kék terület), akkor először kikeressük az intervallum határait (ez ugye kettő érték!) reverz eloszlásfüggvénnyel. Az alsó határ meghatározáshoz tudnunk kell, hogy mekkora a valószínűsége az intervallumunk előtti értékekenek.

```{r normkozepe, fig.cap="Normális eloszlás átlag közeli 25 százalék kiszámítása. Az ábrán látható százalékos értékek az adott intervallumokban a görbe alatti terület nagyságát jelölik százalékosan, $x_1$ és $x_2$ az intervallum határai.", echo=F}
a=qnorm( (1-0.25)/2 )
b=qnorm( 0.5+0.25/2   )
ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(a,b)
                , geom = "area"
                , fill="lightblue"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(b,3)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_label(aes(x=c(-1, 0, 1), y=rep(0.1,3), label=c("37.5%", "25%", "37.5%"), size=3))+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), expression(x[1]), expression(x[2])), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)")
```

Az . ábrán ez az első zöld terület. Ha 0.25 a középső rész, akkor a maradék $1-0.25=0.75$. Azonban ez két egyenlő részre esik, szóval az intervallumunk előtti értékek kumulált valószínűsége $0.75/2=0.375$. Az intervallumunk felső határánál kisebb értékekhez tartozó kumulált valószínűséget ( . ábrán lila terület) pedig úgy kaphatjuk meg, hogy kivonjuk az 1-ből (a teljes eseménytér öszzesített valószínűsége) az adott intervallum feletti értékek kumulált valószínűségét ( . ábrán a zöld terület), az pedig, mint az imént kiszámítottuk $0.75/2=0.375$. Így a keresett valószínűség $1-0.75/2 = 0.625$.

```{r normmasodik25, fig.cap="Normális eloszlás átlag közeli 25 százalék felső határának kiszámítása. Az ábrán látható százalékos értékek az adott intervallumokban a görbe alatti terület nagyságát jelölik százalékosan, $x_1$ és $x_2$ az intervallum határai.", echo=F}
a=qnorm( (1-0.25)/2 )
b=qnorm( 0.5+0.25/2   )
ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,b)
                , geom = "area"
                , fill="purple"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(b,3)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_label(aes(x=c(-0.5, 1), y=rep(0.1,2), label=c("62.5%", "37.5%"), size=3))+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), expression(x[1]), expression(x[2])), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)")
```

A keresett intervallumunk határait tehát így számolhatjuk ki **R**-ben:

```{r}
also = qnorm(0.75/2, mean=0, sd=1)
also
felso = qnorm(1-0.75/2, mean=0, sd=1)
felso
```

Nem meglepő módon ezek abszolútértéke egyenlő, mivel a **standard** normális eloszlás szimmetrikus 0-ra! Az intervallumunk szélessége tehát:

```{r}
felso-also
```

## Exponenciális eloszlás

### Általános leírás

::: {.elmelet data-latex=""}

Exponenciális eloszlás a természetben akkor fordul elő, amikor valaminek van valami állandó megjelenési / eltűnési / átalakulási rátája és mi ennek a valaminek az időbeli előfordulását nézzük. Az exponenciális eloszlás úgy néz ki, hogy valami 0 időpontban teljes mennyiségében előfordul, majd az idő múlásával (az x-tengelyen haladva) ez exponenciálisan csökken. Ez az eloszlás **asszimetrikus**, 1 csúcsa van $f(0)$ -nál és csak 0-tól értelmezzük. Exponenciális eloszlásra példa a radioaktív izotópok bomlása.

:::

Egy paramétere van: $\lambda$, a változás rátája.  

::: {.plusinfo data-latex=""}

Ha $\lambda=0$, az exponenciális függvény sűrűségfüggvénye ( . ábra):

$$e^{-X}$$
```{r}
curve(exp(-x), xlim=c(0,4))
```

Azonban, hogy más rátákhoz is igazíthassuk, a $\lambda$ tagot be kell építeni a függvénybe. 

:::

Így az exponenciális eloszlás sűrűségfüggvénye:

$$f(X)=\lambda e^{-\lambda X}$$

```{r}
lambda = 2
curve(lambda*exp(-x*lambda), xlim=c(0,4), sub=bquote( lambda == 2))
```

Az eloszlásfüggvénye pedig ennek integrálja:

$$F(X)=1-e^{-\lambda X}$$

### Várható érték, variancia 

Az eloszlás várható értéke a rátának a reciproka:

$$E(X)=\frac{1}{\lambda}$$

Ez fontos, mert legtöbbször ilyen formában kapjuk meg az adatokat (pl. valaminek a várható élettartama), amiből vissza kell fejtenünk $\lambda$-t.

Az eloszlás varianciája:

$$SD^2(X)= \frac{1}{\lambda^2}$$

### Valószínűségek számítása

```{r norm, echo=FALSE, fig.cap="Exponenciális eloszlás PDF és CDF"}
a=0.6
plot1 <- ggplot() +
	stat_function(fun = dexp 
                , xlim = c(0,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dexp(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dexp(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dexp, xlim=c(-1,3)) +
	scale_x_continuous(labels=c("0", expression(1 / lambda), "a"), breaks=c(0, 1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dexp(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dexp(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pexp(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pexp(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=pexp, xlim=c(-1,3)) +
	scale_x_continuous(labels=c("0", expression(1 / lambda), "a"), breaks=c(0,1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pexp(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pexp(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```

A . ábrán látható az exponenciális eloszlás sűrűségfüggvénye és eloszlásfüggvénye.  
Az eloszlásfüggvényt a `pexp(..., rate)` függvénnyel lehet kiszámítani, ahol a `rate` a ráta, azaz $\lambda$. Az eloszlásfüggvény inverzét a `qexp(..., rate)` függvénnyel tudjuk kiszámítani. Ha elfelejtenénk, hogy a függvény paraméterei mit jelentenek futtassuk le a `?pexp` parancsot az **R**-ben és a helpből kikereshetjük.

Számoljuk ki mekkora az esélye, hogy egy véletlenszerűen kiválasztott hangya levegőtől elzártan 10 perc múlva nem lesz életben, ha a hangyák várhatóan 15 percig élnek ilyen környezetben!
Ezt leolvashatjuk az ábráról is: kikerssük a CDF-en a 10 percet az x-tengelyen (piros pötty), majd megnézzük milyen y-tengely értéket vesz fel (zöld pötty).  
Ha ki akarjuk számolni, először is meg találnunk $\lambda$-t. Azt tudjuk, hogy a várható érték 15 perc, így $\lambda=1/15$ lesz.
A kiszámoláshoz behelyettesíthetjük a fenti függvénybe is: $1-e^{-1/15 \cdot 10}= 0.49$

Azért **R**-ben ez jóval egyszerűbb:

```{r}
pexp(10, rate=1/15)
```

Arra is kíváncsiak vagyunk, hogy legkevesebb hány percig bírják a hangyák legszívósabb 30%-a?  
Ehhez fordítottan gondolkozunk: meg kell keresnünk, hogy a kevésbé szívós 70% meddig bírja maximum. Ehhez a reverz eloszlásfüggényt használjuk:

$$1-e^{-1/15 \cdot x}= 0.7$$
$$-ln(1-0.7) \cdot 15 = x$$

Tehát $x=18.06$. Ez **R**-ben:

```{r}
qexp(0.7, rate=1/15)
```

## $\chi^2$ eloszlás


```{r chisq, echo=FALSE, fig.cap="Khí négyzet eloszlás PDF és CDF"}
a=30
df=20
plot1 <- ggplot() +
	stat_function(fun = dchisq, args=list(df=df) 
                , xlim = c(-5,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dchisq(c(a,a), df=df)), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf, dchisq(a , df=df))), colour="coral", lwd=1.5)+
	stat_function(fun=dchisq, args=list(df=df), xlim=c(0,df*3)) +
	scale_x_continuous(labels=c("0", "df", "a"), breaks=c(0, df, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dchisq(a, df=df), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dchisq(a, df=df), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pchisq(c(a,a), df=df)), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pchisq(a, df=df) )), colour="coral", lwd=1.5)+
	stat_function(fun=pchisq, args=list(df=df), xlim=c(0,df*3)) +
	scale_x_continuous(labels=c("0", "df", "a"), breaks=c(0, df, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pchisq(a, df=df), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pchisq(a, df=df), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```

## Fischer féle F-eloszlás

```{r feo, echo=FALSE, fig.cap="F- eloszlás PDF és CDF"}
a=2
df1=20
df2=20
if("df" %in% ls())rm(df)
plot1 <- ggplot() +
	stat_function(fun = df, args=list(df1=df1, df2=df2) 
                , xlim = c(0,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= df(c(a,a), df1=df1, df2=df2)), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf, df(a , df1=df1, df2=df2))), colour="coral", lwd=1.5)+
	stat_function(fun=df, args=list(df1=df1, df2=df2), xlim=c(0,df1)) +
	scale_x_continuous(labels=c("0", "df", "a"), breaks=c(0, df1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = df(a, df1=df1, df2=df2), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = df(a, df1=df1, df2=df2), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pf(c(a,a), df1=df1, df2=df2)), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pf(a, df1=df1, df2=df2) )), colour="coral", lwd=1.5)+
	stat_function(fun=pf, args=list(df1=df1, df2=df2), xlim=c(0,df1)) +
	#scale_x_continuous(labels=c("0", expression(1 / lambda), "a"), breaks=c(0,1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pf(a, df1=df1, df2=df2), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pf(a, df1=df1, df2=df2), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```


## Student féle t-eloszlás

```{r teo, echo=FALSE, fig.cap="t- eloszlás PDF és CDF"}
a=-1
df=20
plot1 <- ggplot() +
	stat_function(fun = dt, args=list(df=df) 
                , xlim = c(-5,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dt(c(a,a), df=df)), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf, dt(a , df=df))), colour="coral", lwd=1.5)+
	stat_function(fun=dt, args=list(df=df), xlim=c(-5,5)) +
	#scale_x_continuous(labels=c("0", "df", "a"), breaks=c(0, df, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dt(a, df=df), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dt(a, df=df), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pt(c(a,a), df=df)), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pt(a, df=df) )), colour="coral", lwd=1.5)+
	stat_function(fun=pt, args=list(df=df), xlim=c(-5,5)) +
	#scale_x_continuous(labels=c("0", "df", "a"), breaks=c(0, df, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pt(a, df=df), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pt(a, df=df), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```
