# Folytonos eloszlások


## Folytonos eloszlások általános jellemzése

### Mi az, hogy folytonos?

A diszkrét eloszlásokkal ellentétben a folytonos eloszlások kategóriáit nem tudjuk nevesíteni (értékkészletük határozottan nem megszámlálható!), a valvált **minden** kiválasztott két értéke között tudunk találni végtelen számú más értéket. (Mondhatjuk azt is, hogy folytonos eloszlás esetén a kategóriák "egymásba csúsznak".) Skálájukat tekintve ezek az intervallum és arányskálás változók. Szóval ezek legalább valós számok ($X \in  \mathbb{R}$). Például ide tartoznak minden - nem kategorizáltan - mért hosszúság, idő vagy térfogat adatok. Gondoljunk bele, hogy ha emberek magasságát mérjük, akkor ha van egy 177.01 cm és egy 177.02 cm magas emberünk, attól még megvan a lehetősége annak, hogy találunk egy olyan embert, aki a kettő közözzi magasságú, például 177.014 cm magas. Persze el kell fogadnunk, hogy a mérési hibahatárok miatt nem tudunk végtelen tizedesjegy pontosságig mérni, de a lényeg az, hogy tudjuk, hogy elméletben mérhetnénk addig (vagyis inkább közelíthetően mérhetünk addig).  
Ebből adódik, hogy egy folytonos eloszlás esetén az elemi előfordulás valószínűsége 0 ($P(X=x) = 0$). Például annak a valószínűsége, hogy egy véletlenszerűen kiválasztott ember magassága pontosan 177.02 cm nulla, ugyanis, ha megnéznénk egy sokkal jobb mérési módszerrel, láthatnánk, hogy ez az ember valójában 172.02000000000000000001 cm magas, csak nem tudunk addig mérni.


### Folytonos adatokkal való számolás

|x                        |n            | p        |
|:-----------------------:|:-----------:|:--------:|
| \(\displaystyle x_1 \)  | 1           | 0        |
| \(\displaystyle x_2 \)  | 1           | 0        |
| \(\displaystyle x_3 \)  | 1           | 0        |
| \(\displaystyle x_4 \)  | 1           | 0        |
| \(\displaystyle x_5 \)  | 1           | 0        |
| $\vdots$                | $\vdots$    | $\vdots$ |
| \(\displaystyle x_N \)  | 1           | 0        |


Folytonos eloszlás esetén minden megfigyelés legfeljebb csak egyszer fog előkerülni, így nincs értelme számolni az elemi előfordulások számát, sem a gyakoriságát nézni (előbbi mindig 0 vagy 1, utóbbi mindig 0).  
Ugyan azt nem lehet megmondani, hogy egy valvált **pontosan** megegyezik-e egy adott értékkel ($X ?= x$), azt meg tudjuk mondani, hogy egy adott értéknél kisebb ($X ?\le x$) vagy nagyobb-e ($X ?\ge x$). Így el tudjuk azt is dönteni, hogy bele tartozik-e egy adott intervallumba ($X ?\in [a;b]$). 
Régebben, mikor még nem állt elég számítási kapacitás rendelkezésre, a könnyebb számolás érdekében kategorizálni szokták a folytonos változókat, azaz meg szoktak húzni $\delta x$ szélességű intervallumokat és ebbe szokták belerakni a folytonos változókat (megszámolják hány vátozó esik bele az adott intervallumokba - $n$, illetve kiszámolják ezek gyakoriságát - $p$). Ezt az eljárást hívjuk "diszkretizálás"-nak. Egy ilyet mutat meg a lenti táblázat.


|x intervallum                                                  |n            | p                                                      |
|:-------------------------------------------------------------:|:-----------:|:------------------------------------------------------:|
| \(\displaystyle [x_0; x_0 + \delta x] \)                      | n_1         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + \delta x; x_0 + 2 \delta x)] \)        | n_2         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + 2 \delta x; x_0 + 3 \delta x)] \)      | n_3         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + 3 \delta x; x_0 + 4 \delta x)] \)      | n_4         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| $\vdots$                                                      | $\vdots$    | $\vdots$                                               |
| \(\displaystyle [x_0 + (m-1) \delta x; x_0 + m \delta x)] \)  | n_m         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |

Ennél bonyolultabb, ha a $\delta x$ értékek kategóriánként eltérnek, azaz a diszkrét csoportokat más-més szélességű intervallumok alkotják. A diszkretizált adatokkal való számolást nem tanuljuk a kurzus során (mivel a XXI. században az adna releváns gyakorlati tudást), de a diszkretizálás fogalmával tisztában kell lenni.  


Fontos megkülönböztetni, hogy adatokról vagy eloszlásokról beszélünk-e! A folytonos eloszlások elméleti fogalmak, azok a valós adatoktól függetlenek! Folytonos eloszlásokkal tudjuk **jellemezni** a valós adatokat, de azok nem egyeznek meg, ne keverjük össze a fogalmakat!  

### PDF és CDF

A diszkrét eloszlásokkal ellentétben a folytonos tömegfüggvényeket nem szoktuk valószínűségi tömegfüggvénnyel (PMF) jellemezni (hisz annak értéke mindig 0 lenne), cserébe **sűrűségfüggvénnyel** (PDF = **P**robability **D**ensity **F**unction) jellemezzük. A sűrűségfüggvény a valvált értékeihez olyan értékeket rendel, ami körülbelül azt mutatja meg, hogy mekkora a relatív esélye annak, hogy a valvált adott értékéhez közeli értéket húzunk ki. (Ne felejtsük el, annak az esélye, hogy pontosan egy adott számot húzunk ki 0!) Más megközelítéssel, mekkora az esélye annak, hogy egy random minta átlaga megegyezzen a valvált adott értékével más random mintákhoz képest.  
A sűrűségfüggvény szemléletes megértésében segít, ha elképzeljük, hogy a folytonos valváltot diszkretizáljuk és megnézzünk annak PMF-ét. Ha nagy kategóriákat veszünk ($\delta x$ nagy, azaz a kategóriák száma $m$ kicsi) és összehasolítjuk az eredeti folytonos eloszlás PDF-ével, azt látjuk, hogy bár karakterisztikájában a két függvény hasonlít, azért vannak erős eltérések. Ha azonban kisebb kategóriákat veszünk ($\delta x$ kisebb, azaz a kategóriák száma $m$ nagyobb), a két függvény kezd hasonlítani egymásra. Könnyű elképzelni, hogy ahogy $\delta x$ egyre kisebb lesz, azaz tart a nullához (a valvált egyre inkább kezdi elveszteni diszkrét jellegét), a két függvény kezd egyre jobban hasonlítani egymáshoz. Azonban, míg a diszkrét függvény esetén az y-tengely a valószínűséget mutatta, a folytonos esetén a sűrűséget.  

```{r , fig.cap="Normális (folytonos) eloszlás közelítése binomiális (diszkrét) eloszlással. Az első oszlopban a piros vonalak a normális eloszlás valválthoz tartozó sűrűségfüggvényét (PDF) rajzolják ki, míg a szürke oszlopok a binomiális eloszláshoz tartozó tömegfüggvényét (PMF). A második oszlopban a normális eloszláshoz (piros vonal) és a binomiális eloszláshoz (szürke oszlopok) tartozó eloszlásfüggvények (CDF) vannak. Fentről lefelé soronként nő a binomiális eloszlás mintamérete, azaz a diszkretizálás felbontása."}
prob=0.5
size=3
plot1 <- 
	ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red") +
		labs(title="PMF/PDF" ) +
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot2 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		labs(title="CDF" ) +
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

size=4
plot3 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot4 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())


size=10
plot5 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot6 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())


size=50
plot7 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot8 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

size=150
plot9 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot10 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10, ncol=2)


```


Míg folytonos eloszlás esetén nincs értelme elemi valószínűségeket számolni, intervallumok valószínűségét tudjuk és érdemes kiszámolni. Ezt a sűrűségfüggvényből úgy tudjuk kiszámolni, hogy megnézzük a valvált kijelölt intervallumához tartozó függvény alatti terület nagyságát, azaz az integrálját. Az eloszlásfüggvény ($F(X)$) tehát valójában a sűrűségfüggvény ($f(X)$) integrálja.

$$F(X,x)=\int_{- \infty}^{x} f(X) =P(X \le x)$$

A sűrűségfüggvény határozott intergálja megmutatja, hogy egy véletleszerűen húzott valvált mekkora valószínűséggel vesz fel $a$ és $b$ közötti értéket.

$$\int_A^B f(X) = P(a \le X \le b)$$


Ha a valvált teljes intervallumát nézzük (mínusz végtelentől plusz végtelenig), azt tudjuk, hogy az ahhoz tartozó valószínűség 1, azaz a sűrűségfüggvény határozatlan integrálja 1. (Vagyis a sűrűségfüggvény alatti terület nagysága = 1.)

$$\int_{- \infty }^{+ \infty} f(X) = 1$$

### Valószínűségek számítása

Ha meg akarjuk nézni, hogy egy valvált mekkora valószínűséggel vesz fel egy adott $a$ értéknél kisebbet, akkor így számoljuk ki:

$$P(X \le a) =F(a) = \int_{- \infty}^{a} f(X)$$

Ne felejtsük el, hogy mivel az elemi előfordulás valószínűsége 0 ($P(X=a)=0$), ezért $P(X \le a) = P(X < a)$!

Előbbi valószínűséget a sűrűségfüggvényről úgy lehet "leolvasni", hogy x tengelyen kikeressük $a$ értékét (piros pont az ábrán) és megnézzük, hogy mekkora az $a$ pont előtt a függvény alatti (az ábrán zöld) terület nagysága. Természetesen ezt ténylegesen leolvasni nem tudjuk. A CDF-ről viszont igen, csak meg nézni, hogy a valvált adott értékéhez milyen érték tartozik az y-tengelyen (zöld pötty). 

```{r}
a=2
plot1 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pnorm(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=pnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pnorm(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)

```

Azonban, ha arra vagyunk kíváncsiak, hogy milyen valószínűséggel vesz fel egy adott értéknél

Ha blokkokra / intervallumokra vagyunk kíváncsiak, akkor is használható a fenti módszer, de egyszerűbb ha az eloszlásfüggvénnyel számolunk. Ha pl. arra vagyunk kíváncsiak, hogy mekkora eséllyel vesz fel egy valvált egy adott $x$ értékkel megegyező vagy kisebb értéket. Ha másfajta intervallumokra vagyunk kíváncsiak, akkor használjuk fel a következő összefüggést:

$$\sum_{x=0}^{max} P(X=x) = 1$$

vagyis az összes eset valószínűségének összege 1.  
Ha tehát arra vagyunk kíváncsiak, hogy mekkora eséllyel vesz fel egy valvált egy adott $x$ értékkel megegyező vagy nagyobb értéket, akkor az eloszlásfüggvény segítségével kiszámolhatjuk, hogy mekkora valószínűséggel vesz fel $x-1$-et vagy annál kisebbet és ezt kivonjuk 1-ből.  

$$P(X \ge x) = 1 - P(X \le x-1)$$

Ha több intervallumhatárral (pl. "A" és "B") dolgozunk, nehezedik a dolgunk.  
$$P(legalább ~A ~és~ legfeljebb ~B) = P(X \le B) - P(X \le A-1)$$

Ebben az esetben először kiszámoljuk $P(X \le B)$-t (Step 1 zöld rész), majd kivonjuk belőle azt a részt, ami nem kell (Step 2 piros rész), ez pedig $P(X \le A-1)$ és ami marad az a végeredmény (Result). Azért $A-1$, mert a "legalább A" -ban benne van az $A$, így az nem szabad kivonni végeredményből!

```{r , echo=F, fig.height=2, fig.cap="Legalább A és legfeljebb B kiszámolása"}

p1 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("green",15), rep("green",5),rep("grey",41-15-5))))) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	scale_x_continuous(labels=c("A", "B"), breaks=c(14 , 19))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("red"="coral","green" = "lightgreen", "grey" = "grey40"))+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Step 1")


p2 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("red",14), rep("green",6),rep("grey",41-15-5))))) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	scale_x_continuous(labels=c("A", "B"), breaks=c(14 , 19))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("red"="coral","green" = "lightgreen", "grey" = "grey40"))+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Step 2")

p3 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("grey",14), rep("green",6),rep("grey",41-15-5))))) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	scale_x_continuous(labels=c("A", "B"), breaks=c(14 , 19))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("red"="coral","green" = "lightgreen", "grey" = "grey40"))+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Result")


grid.arrange(p1, p2, p3, ncol=3)
```

$$P(maximum ~A ~vagy~ minimum ~B) = 1- (P(X \le B-1) - P(X \le A))=1- P(X \le B-1) + P(X \le A)$$
Ehhez először kiszámoljuk a "minimum B" részt: $1- (P(X \le B-1)$ (Step 1 zöld). Azért $B-1$, mert a "minimum B" -ben benne van a $B$, így az nem szabad kivonni! Majd ehhez hozzáadjuk a "maximum A" részt: $P(X \le A)$ (Step 2 másik zöld rész).

```{r , fig.cap="maximum A vagy minimum B kiszámolása", echo=F, fig.height=2}

p1 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("grey",15), rep("grey",4),rep("green",41-15-4))))) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	scale_x_continuous(labels=c("A", "B"), breaks=c(14 , 19))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("red"="coral","green" = "lightgreen", "grey" = "grey40"))+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Step 1")


p2 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("green",15), rep("grey",4),rep("green",41-15-4))))) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	scale_x_continuous(labels=c("A", "B"), breaks=c(14 , 19))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("red"="coral","green" = "lightgreen", "grey" = "grey40"))+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Step 2")


grid.arrange(p1, p2, nrow=1)
```


Figyeljünk a következő szinonimákra és arra, hogy ne keverjük őket:

  * "$x$ és nagyobb", "legalább $x$", "minimum $x$", "nem kevesebb mint $x$" 
  * "$x$-nél nagyobb", "több mint $x$"
  * "$x$ és kisebb", "legfeljebb $x$", "maximum $x$", "nem több mint $x$"
  * "$x$-nél kisebb", "kevesebb mint $x$"

Néha visszafelé is számolni kell: adott egy valószínűségi érték és ehhez kell kiszámolni, hogy a valvált melyik értéktartományához tartozik tartozik. Ezt a reverz CDF-el tudjuk kiszámolni.

**R**-ben a PMF-et, a CDF-et és a reverzét a `d...()`, `p...()` és `q...()` formájú függvényekkel fogjuk elérni.

$$
\begin{gathered}
valvált \rightarrow \mathbf{d} \rightarrow P(X=x) \\
valvált \rightarrow \mathbf{p} \rightarrow P(X \le x) \\
P(X \le x) \rightarrow \mathbf{q} \rightarrow valvált 
\end{gathered}
$$

## Egyenletes eloszlás

### Általános leírás

Az egyenletes eloszlás az, amikor minden érték egyforma valószínűséggel fordul elő. Ez leggyakrabban a "dobtam egy dobókockával" kezdetű statisztikafeladatok esetén fordul elő a természetben.  
Az egyenletes eloszlás két paramétere a *minimum* és *maximum* érték. E két érték közt minden kategória gyakorisága megegyezik. Tehát

$$P(X=x) = \frac{1}{N}$$

amiben $N$ a kategóriák száma.  

### Várható érték, variancia

Az eloszlás várható értéke a valvált minimuma és maximuma által jelzett intervallum közepe:

$$E(X)= \frac { max(X) + min(X) }{2}$$

Az eloszlás varianciája:

$$SD^2(X)=\frac {N^2-1}{12}$$


Tegyük fel, hogy ki akarjuk számítani, hogy szabályos dobókocka esetén mekkora a várható érték (az ábrán lila vonal), variancia, szórás! Az eloszlásra specifikus képletekkel:

```{r}
x <- 1:6
n <- length(x) #kategoriak szama

(max(x)+min(x))/2 #varhato ertek
(n^2-1)/12 #variancia
sqrt((n^2-1)/12) #szoras
```

Általános képletekkel:

```{r}
x <- 1:6
n <- length(x) #kategoriak szama
p <- rep(1/n, n ) #kategoriak gyakorisaga: 1/6, 1/6, 1/6, 1/6, 1/6 es 1/6

sum(p*x) #varhato ertek
sum(p*x^2) - sum(p*x)^2 #variancia
sqrt(sum(p*x^2) - sum(p*x)^2) #szoras
```

### Valószínűségek számítása


```{r discrunif, fig.cap="Egyenletes eloszlás PMF és CDF\\label{discrunif}", echo=FALSE}


plot1 <- ggplot(data.frame(x=5:10, col=as.character(c(rep("green",3),rep("grey",3)))), aes(x)) +
	geom_step(aes(x, y), data=data.frame(	x= c(7, -Inf),	y= c(1/6,1/6)), colour="lightblue", lwd=1.5)+
  #geom_bar(aes(y = ..prop.., fill=col)) +
	geom_bar(aes(y = ..count.. / sum(..count..), fill=col)) +
	#xlim(0,15)+
	#scale_x_discrete(labels=c("5"="min", "7"="x", "10"="max"))
	scale_x_continuous(labels=c("min", "a", "M", "max"), breaks=c(5,7, 7.5 ,10), limits=c(0,15))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "grey40"))+
	annotate(geom = "point", x = -Inf, y = 1/6, size = 2, color = 'blue')+
	annotate(geom = "point", x = 7, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Probability Mass Function") +
	geom_vline(xintercept = (5+10)/2, col="purple")


plot2 <- ggplot(data.frame(x=0:15, y=punif(0:15, min=4, max=10) ))+
	geom_step(aes(x, y), data=data.frame(	x= c(7, -Inf),	y= c(3/6,3/6)), colour="lightgreen", lwd=1.5)+
	geom_bar(aes(x=x, y=y), stat="identity")+
	scale_x_continuous(labels=c("min", "a", "M", "max"), breaks=c(5,7, (5+10)/2,10))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "darkgrey"))+
	annotate(geom = "point", x = -Inf, y = 3/6, size = 2, color = 'green4')+
	annotate(geom = "point", x = 7, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y=expression(P(X <= x) ), title="Cumulative Density Function")+
	geom_vline(xintercept = (5+10)/2, col="purple")


grid.arrange(plot1, plot2, ncol=2)
```

A . ábrán látható a diszkrét egyenletes eloszlás tömegfüggvénye és eloszlásfüggvénye. A PMF-en látható, hogy a minimum és maximum között egyenlő valószínűséggel húzhatunk ki számokat, míg azokon kívül nem húzhatunk ki. Mint ahogy a szabályos dobókockával sem dobhatunk -2-t, vagy 7-et. A CDF-en látszik, hogy ha $x \ge max$, akkor annak a valószínűsége, hogy kisebbet vagy egyenlőt dobunk $x$-el egyenlő 1, tehát biztosan. Dobókocka esetén tehát biztos, hogy kisebbet dobunk, mint 10.  

Ha ki szeretnénk számolni, hogy mennyi az esélye, hogy $a=3$ -at dobunk a dobókockával, leolvashatjuk a grafikonokról: A PMF-en kikeressük az x-tengelyen a 3-at (piros pötty), majd a hozzá tartozó oszlopról leolvassuk az y-tengelyen a valószínűséget (kék pötty); a CDF -en pedig leolvassuk a 3-hoz tatozó kumulált valószínűséget (zöld pötty) majd kivonjuk az egyel kisebb kategóriához tartozó kumulált valószínűséget (nincs ábrázolva). De legegyszerűbb kiszámolni: 1 osztva a kategóriák számával, tehát 1/6.  
Ha ki szeretnénk számolni, hogy mennyi az esélye, hogy $a=3$ -at vagy kisebbet dobunk a dobókockával, leolvashatjuk a grafikonokról: A PMF-en kikeressük az x-tengelyen a 3-at (piros pötty), majd a hozzá tartozó és annál kisebb oszlopokról (zöld oszlopok) leolvassuk az y-tengelyen a valószínűségeket és összeadjuk; a CDF -en pedig leolvassuk a 3-hoz tatozó kumulált valószínűséget (zöld pötty). De ki is számolhatjuk: ez 3 kategória (1,2,3-ast dobunk), tehát 3 * 1/6 = 3/6 = 0.5. 

## Hipergeometrikus eloszlás

### Álatlános leírás

Hipergeometrikus eloszlás esetén mintákat veszünk egy bináris objektumokat (ezt keresem - nem ezt keresem) tartalmazó populációból és a valószínűségi változó természetes szám lesz, ami meghatározza, hogy hány olyan objektum van a mintában, amilyet keresek. Fontos, hogy megadott a minta mérete (hány objektumot veszek ki) és az, hogy az eredeti populációban milyen az aránya annak az objektumnak, amilyet keresek. **Fontos**: hipergeometrikus eloszlás esetén a mintavétel során **változik a megfelelő objektumok aránya a populációban**! Például, ha egy urnában van 6 fehér golyóm és 4 fekete, annak a valószínűsége, hogy egyet húzok és fehér lesz az $P(első ~ fehér) = 6/10 = 0.6$. Viszont ha kihúzok egy másodikat is az urnából, akkor annak a valószínűsége, hogy fehér lesz, már nem ennyi, attól függően elsőre mit húztam ki. Ha elsőre fehért húztam ki, már csak 5 fehér van az urnában, tehát $P(második ~ fehér ~ ha ~ első ~ fehér) = 5/9 = 0.5556$, ha viszont feketét húztam, úgy "csak" a golyók össz száma csökkent, tehát $P(második ~ fehér ~ ha ~ első ~ fekete) = 6/9 = 0.6667$. Vagyis, az elemi események hipergeometrikus eloszlás esetén **nem független**ek egymástól.
A természetben ez a fajta eloszlás előfordul ugyan kis populációknál, ha adott tulajdonságú egyedeket keresünk, de gyakorlatilag biológusok sosem számolnak vele.

A hipergeometrikus eloszlás fő paraméterei: 

* $m$: a *megfelelő* objektumok száma a kiindulási populációban
* $n$: a *nem megfelelő* objektumok száma a kiindulási populációban
* $k$: a mintavétel során kihúzott objektumok száma, a *minta nagysága*
	
Annak a valószínűségét, hogy $x$ db megfelelő objektumot veszünk ki a mintából, a következőképpen számolhatjuk ki:

$$P(X=x) = \frac{n_{megfelelő ~ kombinációk}}{n_{összes ~ kombinációk}} = \frac{ {m \choose x}{ {n \choose {k-x} }} }{ {{m+n} \choose k} }$$

A kombináció $N \choose n$ ugye azt mutatja meg, hogy hányféleképpen húzhatunk ki egy $N$ elemű halmazból $n$ elemű részhalmazt. Ezt a műveletet tudományos számológépeken legtöbbször az "nCr" gombbal hívhatjuk elő, **R**-ben így:

```{r}
choose(8, 2) #combination: 10C2
combn(8, 2) #kidobja az osszes kombinaciot 
```

A fenti képletben az $m+n$ a kiindulási pool mérete, tehát ennyi objektumunk van összesen. Tehát $m+n \choose k$ azt jelenti, hogy összesen ennyiféleképpen húzhatunk ki $k$ darab objektumot a poolból. A tört számlálójában a nekünk megfelelő esetek száma van. $m \choose x$ azt jelzi, hogy hányféleképp tudjuk a kellő $x$ számú megfelelő objektumot kihúzni, ha összesen $m$ ilyen objektum van a poolban, Ez nekünk azonban nem elég, elő kell húznunk $k-x$ számú nem megfelelő objektumot is, mert ha nem tennénk, akkor a maradék golyó lehetne bármilyen, ez azonban nem lenne jó nekünk, tekintve, hogy pontosan $x$ darab jót akarunk kihúzni és nem többet. Tehát $n \choose k-x$ féleképpen tudjuk kihúzni $n$ nem megfelelő objektumból $k-x$ jót. Mivel független elemi események esetén $P(A|B)=P(A)P(B)$, ezért a nekünk megfelelő jó húzások száma ${m \choose x}* { n \choose {k-x} }$. 

### Várható érték, variancia

Az eloszlás várható értéke a minta elemszáma szorozva a megfelelő objektumok eredeti gyakoriságával 

$$E(X)= kp= k \frac{m}{m+n}$$

Az eloszlás varianciája:

$$SD^2(X)= kp(1-p)(1-\frac{k-1}{m+n-1})$$

Számoljuk ki egy hipergeometrikus eloszlás várható értékét és varianciáját! Tegyük fel, hogy van egy 30 kacsát tartalmazó tavunk, mely kacsák 60% -a hím. Ezek közül véletlenszerűen lelövünk 6-ot. Számoljuk ki annak az eloszlásnak a várható értékét és varianciáját, amelyik azt írja le, hány gácsér van a lelőtt kacsák között!

Az eloszlásra specifikus képletekkel:

```{r}
N=30 # ennyi kacsa van osszesen
k = 6 # ennyi kacsat lovunk le
m = N*0.6 # 18 : ennyi kacsa him 
n = 30-m # 12 : ennyi kacsa nosteny
M = k*m/N # varhato ertek : ugye (m+n) = N
M

k * m/N*(1-m/N)*(1-(k-1)/(N-1)) #variancia
```

Általános képletekkel:

```{r}
N=30 # ennyi kacsa van osszesen
k = 6 # ennyi kacsat lovunk le
m = N*0.6 # 18 : ennyi kacsa him 
n = 30-m # 12 : ennyi kacsa nosteny

x <- 0:6 # ennyi lelott kacsa lehet him
p <- dhyper(x, m=m, n=n, k=k) #kategoriak gyakorisaga
```

A fenti függvény (`dhyper(x, m=m, n=n, k=k)`) az $x$-hez tartozó valószínűségeket számolta ki. Erről bővebben a következő alfejezetben lesz szó.  
Mivel így már ismertek a válvált lehetséges értékei és azok valószínűsége, a várható érték és a variancia kiszámítása általános képletekkel:

```{r}
sum(p*x) #varhato ertek
sum(p*x^2) - sum(p*x)^2 #variancia
sqrt(sum(p*x^2) - sum(p*x)^2) #szoras
```

### Valószínűségek számítása


```{r hypergeom, echo=FALSE, fig.cap="Hipergeometrikus eloszlás PMF és CDF. Az eloszlás paraméterei: *m* = 18, *n*= 12, *k* = 6\\label{hyperg}"}


plot1<-ggplot(data.frame(x=0:6,y=dhyper(0:6,m=18, n=12, k=6), col=as.character(c(rep("green",3),rep("grey",4)))), aes(x)) +
	geom_step(aes(x, y), data=data.frame(	x= c(2, -Inf),	y= dhyper(c(2,2),m=18, n=12, k=6)), colour="lightblue", lwd=1.5)+
  #geom_bar(aes(y = ..prop.., fill=col)) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	#xlim(0,15)+
	#scale_x_discrete(labels=c("5"="min", "7"="x", "10"="max"))
	scale_x_continuous(labels=c("0", "a", "M", "k"), breaks=c(0, 2, 6*18/30,6))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "grey40"))+
	annotate(geom = "point", x = -Inf, y = dhyper(2,m=18, n=12, k=6), size = 2, color = 'blue')+
	annotate(geom = "point", x = 2, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Probability Mass Function")


plot2 <- ggplot(data.frame(x=0:6,y=phyper(0:6,m=18, n=12, k=6)) )+
	geom_step(aes(x, y), data=data.frame(	x= c(2, -Inf),	y= phyper(c(2,2),m=18, n=12, k=6)), colour="lightgreen", lwd=1.5)+
	geom_bar(aes(x=x, y=y), stat="identity")+
	scale_x_continuous(labels=c("0", "a", "M", "k"), breaks=c(0, 2, 6*18/30,6))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "darkgrey"))+
	annotate(geom = "point", x = -Inf, y = phyper(2,m=18, n=12, k=6), size = 2, color = 'green4')+
	annotate(geom = "point", x = 2, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y=expression(P(X <= x) ), title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```

A . ábrán látható a hipergeometrikus eloszlás tömegfüggvénye és eloszlásfüggvénye.  
Ezeket **R**-ben vagy a fenti képlettel, vagy specifikus függvényekkel tudjuk kiszámolni. A tömegfüggvényt a `dhyper(..., m, n, k)` függvénnyel, az eloszlásfüggvényt pedig a `phyper(..., m, n, k)` függvénnyel. Az eloszlásfüggvény inverzét a `qhyper(..., m, n, k)` függvénnyel tudjuk kiszámítani. Ha elfelejtenénk, hogy a függvény paraméterei mit jelentenek futtassuk le a `?dhyper` parancsot az **R**-ben és a helpből kikereshetjük.


Számoljuk ki mennyi az esélye, hogy páratlan számú hím kacsát lövünk le a hatból! Ez ugye a következő esetekben fordulhat elő: $x={1;3;5}$. Azaz ki kell számolni:

$$P(páratlan ~ hím)=P(X=1)+P(X=3)+P(X=5)= \\ \frac{ {18 \choose 1}{ 12 \choose {6-1} } }{ {30 \choose 6} } +\frac{ {18 \choose 3}{ 12 \choose {6-3} } }{ {30 \choose 6} } + \frac{ {18 \choose 5}{ 12 \choose {6-5} } }{ {30 \choose 6} }$$

**R**-ben:

```{r}
dhyper(1, m=18, n=12, k=6) + dhyper(3, m=18, n=12, k=6) + dhyper(5, m=18, n=12, k=6)
#vagy
sum( dhyper(c(1,3,5), m=18, n=12, k=6) )
```

Számoljuk ki, mennyi az esélye annak, hogy több mint 2 hím van a lelőtt kacsák között. Ezt kiszámolhatjuk az előző módon is:

$$P(több ~ mint ~ 2 ~ hím)=P(X=3) + P(X=4) + P(X=5) + P(X=6)$$

Vagy kihasználva, hogy $\sum P_i =1$ kivonjuk az 1-ből az $X={0,1,2}$ esetek valószínűségét (lásd: PMF zöld oszlopok).

$$P(több ~ mint ~ 2 ~ hím)= 1- \left ( P(X=2) + P(X=1) + P(X=0) \right ) = 1- P(X=2) - P(X=1) - P(X=0) $$

De sokkal egyszerűbb, ha az eloszlásfüggvényt kihasználva kivonjuk az 1-ből a $P(X \le 2)$ valószínűségét (PMF: zöld oszlopok, CDF: zöld pont).

$$P(több ~ mint ~ 2 ~ hím)= 1- P(X \le 2) $$

Ez utóbbi **R**-ben:

```{r}
1 - phyper(2, m=18, n=12, k=6)
```

Számoljuk ki, hogy az esetek alsó 15%-ában maximum hány hím kacsát lövünk ki! A CDF-en ki kell keresni az y-tengelyen a 0.15 -öt (zöld pötty), majd megkeresni, hogy melyik az a legnagyobb oszlop, ami még alatta van (piros pötty). **R**-ben egyszerűbb:

```{r}
qhyper(0.15, m=18, n=12, k=6)
```
Azaz maximum 2 hím kacsa lesz a lelőttek között az esetek alsó 15%-ában.

## Binomiális eloszlás

### Általános leírás

Binomiális eloszlás esetén mintákat veszünk egy bináris objektumokat (ezt keresem - nem ezt keresem) tartalmazó populációból és a valószínűségi változó természetes szám lesz, ami meghatározza, hogy hány olyan objektum van a mintában, amilyet keresek. Fontos, hogy megadott a minta mérete (hány objektumot veszek ki) és az, hogy a populációban milyen az aránya annak az objektumnak, amilyet keresek. **Fontos**: binomiális eloszlás esetén a mintavétel során **nem változik a megfelelő objektumok aránya a populációban**, a megfelelő objektumok kihúzásának valószínűsége állandó! Vagyis, az elemi események megtörténte binomiális eloszlás esetén **független** egymástól.  
Tehát a legegyszerűbben úgy lehet választani aközül, hogy egy eloszlás hipergeometrikus vagy binomiális, hogy megnézzük, hogy ha kihúzok a pool-ból egy objektumot változik-e a valószínűsége annak, hogy egy második húzás során nekem megfelelő objektumot húzok ki:

* ha változik: hipergeometrikus
* ha nem változik: binomiális

A természetben ez a fajta eloszlás gyakran előfordul ha **nagy** populációk esetén keresünk valamilyen tulajdonság meglétét, tehát az előfordulásnak van egy adott rátája. Főleg az ökológusok és statisztikával többet foglalkozó genetikusok fognak ezzel sokat találkozni.

A binomiális eloszlás fő paraméterei:

* $p$: a megfelelő objektumok *aránya* a populációban
* $n$: a mintavétel során kihúzott objektumok száma, a *minta nagysága*

Annak a valószínűségét, hogy $k$ db megfelelő objektumot veszünk ki a mintából, a következőképpen számolhatjuk ki:  
Először is vegyük azt, hogy mennyi az esélye, hogy egy random kihúzott objektum megfelelő - ez ugye $p$. Mivel függetlenek egymástól az elemi események, ezért annak a valószínűsége, hogy 2 kihúzott objektumból 2 megfelelő $p *p=p^2$, annak a valószínűsége pedig, hogy $k$ kihúzott objektumból $k$ megfelelő $p^k$. Ezt megszorozzuk azzal, hogy hányféleképpen lehet az $n$ nagyságú mintából $k$ objektumot kiválogatni, ami ugye $n \choose k$. Ezzel még nem végeztünk, mert számolni kell azzal, hogy a minta maradékának ($n-k$) a másik típusból kell lennie. Annak a valószínűsége, hogy egy random objektum a másik típusú lesz $1-p$. Így annak a valószínűsége, hogy $n-k$ objektum a másik típusú lesz $(1-p)^{n-k}$. A képlet összerakva:

$$P(X=k) = {n \choose k} p^k (1-p)^{n-k}$$

### Várható érték, variancia

Az eloszlás várható értéke a minta elemszáma szorozva a megfelelő objektumok gyakoriságával 

$$E(X)= np$$

Az eloszlás varianciája:

$$SD^2(X)= np(1-p)$$

Számoljuk ki egy binomiális eloszlás várható értékét és szórását! Tegyük fel, hogy van egy génváltozat ami az emberi populáció 2/5-ében megtalálható. Számítsuk ki annak az eloszlásnak a várható értékét és szórását ami azt mutatja meg hány emberben van meg ez a génváltozat, ha 40 véletlenszerűen kiválasztott emberből álló mintát veszünk!

Az eloszlásra specifikus képletekkel:

```{r}
n = 40
p = 0.4

n*p # varhato ertek

n*p*(1-p) # variancia
sqrt(n*p*(1-p)) # szoras
```

Általános képletekkel:

```{r}
x <- 0:40 # ennyi ember tartalmazza lehetsegesen a gent
p <- dbinom(x, size = n, prob = 0.4) #kategoriak gyakorisaga
```

A fenti függvény (`dbinom(x, size = n, prob = 0.4)`) az $x$-hez tartozó valószínűségeket számolta ki. Erről bővebben a következő alfejezetben lesz szó.  
Mivel így már ismertek a válvált lehetséges értékei és azok valószínűsége, a várható érték és a variancia kiszámítása általános képletekkel:

```{r}
sum(p*x) #varhato ertek
sum(p*x^2) - sum(p*x)^2 #variancia
sqrt(sum(p*x^2) - sum(p*x)^2) #szoras
```

### Valószínűségek számítása


```{r binom, echo=FALSE, fig.cap="Binomiális eloszlás PMF és CDF. Az eloszlás paraméterei: *n* = 40, *p* = 0.4 \\label{bino}"}

plot1 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("green",15),rep("grey",26))))) +
	geom_step(aes(x, y), data=data.frame(	x= c(14, -Inf),	y= dbinom(c(14,14),size=40, prob=0.4)), colour="lightblue", lwd=1.5)+
  #geom_bar(aes(y = ..prop.., fill=col)) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	#xlim(0,15)+
	#scale_x_discrete(labels=c("5"="min", "7"="x", "10"="max"))
	scale_x_continuous(labels=c("0", "a", "M", "n"), breaks=c(0, 14 , 0.4*40,40))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "grey40"))+
	annotate(geom = "point", x = -Inf, y = dbinom(14,size=40, prob=0.4), size = 2, color = 'blue')+
	annotate(geom = "point", x = 14, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Probability Mass Function")


plot2 <- ggplot(data.frame(x=0:40,y=pbinom(0:40, size=40, prob=0.4)) )+
	geom_step(aes(x, y), data=data.frame(	x= c(14, -Inf),	y= pbinom(c(14,14),size=40, prob=0.4)), colour="lightgreen", lwd=1.5)+
	geom_bar(aes(x=x, y=y), stat="identity")+
	scale_x_continuous(labels=c("0", "a", "M", "n"), breaks=c(0, 14 , 0.4*40,40))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "darkgrey"))+
	annotate(geom = "point", x = -Inf, y = pbinom(14,size=40, prob=0.4), size = 2, color = 'green4')+
	annotate(geom = "point", x = 14, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y=expression(P(X <= x) ), title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=1)
```

A . ábrán látható a binomiális eloszlás tömegfüggvénye és eloszlásfüggvénye.  
Ezeket **R**-ben vagy a fenti képlettel, vagy specifikus függvényekkel tudjuk kiszámolni. A tömegfüggvényt a `dbinom(..., size, prob)` függvénnyel, az eloszlásfüggvényt pedig a `pbinom(..., size, prob)` függvénnyel, ahol a `size` a mintaméret, azaz $n$, a `prob` pedig az elemi esemény valószínűsége, tehát $p$. Az eloszlásfüggvény inverzét a `qbinom(..., size, prob)` függvénnyel tudjuk kiszámítani. Ha elfelejtenénk, hogy a függvény paraméterei mit jelentenek futtassuk le a `?dbinom` parancsot az **R**-ben és a helpből kikereshetjük.


Számoljuk ki mennyi az esélye, hogy nem pontosan 14 ember ember tartalmazza ezt gént! Ezt úgy lehet legegyszerűbben kiszámolni, hogy az 1-ből kivonjuk annak a valószínűségét, hogy 14 ember (PMF: piros pont) tartalmazza a gént (PMF: kék pont).

$$P(nem ~ 14)=1-P(X=14)= 1- {40 \choose 14} 0.4^{14} (1-0.4)^{40-14}$$

**R**-ben:

```{r}
1 - dbinom(14, size=40, prob=0.4)
```

Számoljuk ki mennyi az esélye annak, hogy legfeljebb 14 vagy legalább 26 emberben benne van a gén! Ehhez részfeladataira bontjuk a feladatot: ki kell számolni mennyi az esélye, hogy 14 vagy kevesebb embernek van (PMF: zöld oszlopok; CDF: zöld pötty) és ehhez hozzá kell adni annak a valószínűségét, hogy legalább 25 embernek van.

$$P(legfeljebb ~ 14 ~ vagy ~ legalább ~ 26)=P(legfeljebb ~ 14) + P(legalább ~ 26)= $$
$$ P(X \le 14) + (1-P(X \le 25))= 1-P(X \le 25) + P(X \le 14)  $$

**R**-ben:

```{r}
1 - pbinom(25, size=40, prob=0.4) + pbinom(14, size=40, prob=0.4)
```

Számítsuk ki, hogy ha a "sok génhordozó" kategóriában az adatok 30%-van, hány, az adott gént tartalmazó embertől mondjuk, hogy "sok a génhordozó"?  
Ugye, ha sok a gén, akkor az eloszlás "jobb oldali" végére vagyunk kíváncsiak, tehát a 40 génhordozó felé keresünk. Azt nem tudjuk, hogy ebbe melyik értékek tartoznak, de azt igen, hogy ezeknek az értékeknek a gyakoriságainak összege 30%. Tehát nekünk most az eloszlásfüggvény inverze kell! Azonban az azt számolja ki, hogy adott valószínűséghez tartozó értékek közül melyik a legnagyobb. Ezért nekünk először a legkisebb 70% -ot kell kiszámolni.
```{r}
qbinom(0.7, size=40, prob=0.4)
```

Ez a 18-as. Tehát a 18 még az előző kategóriába tartozik, tehát a sok génhordozó" kategória 19 az adott gént tartalmazó embertől tart.

## Poisson eloszlás

### Általános leírás

A Poisson eloszlás objektumok térben vagy időben való **véletlenszerű** eloszlását modellezi. Ebben az esetben is nekünk fontos objektumokat keresünk és mintákat veszünk, viszont itt csak azokat az objektumokat számoljuk meg (és nem számoljuk azokat amiket nem keresünk) és mintát úgy veszünk, hogy megfigyelünk adott méretű térrészt (pl. fa hektáronként vagy homoszemcse literenként) vagy adott hosszúságú időtartamot (pl. vízcsepp percenként). Fontos, hogy a megfigyelt idő-, vagy térrészek nem fedik egymást, azaz az elemi események megtörténte Poisson eloszlás esetén **független** egymástól.  

A természetben ez a fajta eloszlás van, ha nincs mechanizmus, ami miatt ettől eltérnek az objektumok. Ökológusok, etológusok és mikroszkópos biológusok (élet-, sejttanászok) számára ez az egyik legfontosabb eloszlás, tekintve ha a Poisson eloszlástól való eltérést érzékelnek, megéri vizsgálódni azért, hogy megtalálják azt a háttérmechanizmust, ami miatt nem random fordulnak elő az objektumok (taszítják vagy vonzzák egymást aktívan).

A Poisson eloszlásnak egy paramétere van ($\lambda$), ami az eloszlás **várható értéke** és **varianciá**ja is egyben! A $\lambda$-t át lehet skálázni más mintaméretre!

$$M(X)=SD^2(X)=\lambda$$

```{r}
curve(log(x))
```


Az eloszlást a természetes logaritmus alapját képező Euler féle $e$ szám segítségével vezethetjük le.

$$e = \sum_{i=0}^{\infty}\frac{1}{i!}=\frac{1}{0!} + \frac{1}{1!}+ \ldots +\frac{1}{\infty!}$$

Ez nagyszerű, csak az a baj, hogy 1-re van skálázva. Viszont nem csak 1-es várható értékű eloszlásokat szeretnénk számolni, így emeljük $\lambda$ hatványára !

$$e^{\lambda} = \sum_{i=0}^{\infty} \lambda^i\frac{1}{i!}=\lambda^0\frac{1}{0!} + \lambda^1 \frac{1}{1!}+ \ldots +\lambda^\infty \frac{1}{\infty!}$$

Egy valószínűségi eloszlás esetén a tagok összege 1. $e^{\lambda}$ pedig akkor lesz egy, ha megszorozzuk a reciprokával!

$$ 1 = e^{\lambda} e^{-\lambda} =  \sum_{i=0}^{\infty} e^{-\lambda}\frac{\lambda^i}{i!}=e^{-\lambda} \frac{\lambda^0}{0!} + e^{-\lambda} \frac{\lambda^1}{1!}+ \ldots + e^{-\lambda} \frac{\lambda^\infty}{\infty!}$$

Ez ugye egy végtelen sorozat, ami leírja a valószínűségi eloszlást. Ha ebből kivesszük mondjuk a 2. tagot ($e^{-\lambda} \lambda^1 / 1!$), akkor megkapjuk, hogy mekkora a valószínűsége, hogy véletlenszerű eloszlás esetén 1 objektumot találok a mintámban, $\lambda$ várható érték mellett. Ezt általánosítva:

$$P(X=k)= e^{-\lambda}\frac{\lambda^k}{k!} $$

### Valószínűségek számítása

```{r pois, echo=FALSE, fig.cap="Poisson eloszlás PMF és CDF. \\label{poi}"}

plot1 <- ggplot(data.frame(x=0:40,
									y=dpois(0:40, lambda=25), 
									col=as.character(c(rep("green",35),rep("grey",6))))) +
	geom_step(aes(x, y), data=data.frame(	x= c(34, -Inf),	y= dpois(c(34,34), lambda=25)), colour="lightblue", lwd=1.5)+
  #geom_bar(aes(y = ..prop.., fill=col)) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	#xlim(0,15)+
	#scale_x_discrete(labels=c("5"="min", "7"="x", "10"="max"))
	scale_x_continuous(labels=c("0", expression(lambda), "a"), breaks=c(0, 25, 34))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "grey40"))+
	annotate(geom = "point", x = -Inf, y = dpois(34, lambda=25), size = 2, color = 'blue')+
	annotate(geom = "point", x = 34, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Probability Mass Function")


plot2 <- ggplot(data.frame(x=0:40,
									y=ppois(0:40, lambda=25)) )+
	geom_step(aes(x, y), data=data.frame(	x= c(34, -Inf),	y= ppois(c(34,34),lambda = 25)), colour="lightgreen", lwd=1.5)+
	geom_bar(aes(x=x, y=y), stat="identity")+
	#scale_x_continuous(labels=c("min", "a", "max"), breaks=c(5,7,10))+ 
	scale_x_continuous(labels=c("0", expression( lambda ), "a"), breaks=c(0, 25, 34))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "darkgrey"))+
	annotate(geom = "point", x = -Inf, y = ppois(34,lambda=25), size = 2, color = 'green4')+
	annotate(geom = "point", x = 34, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y=expression(P(X <= x) ), title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=1)
```

A . ábrán látható a Poisson eloszlás tömegfüggvénye és eloszlásfüggvénye.  
Ezeket **R**-ben vagy a fenti képlettel, vagy specifikus függvényekkel tudjuk kiszámolni. A tömegfüggvényt a `dpois(..., lambda)` függvénnyel, az eloszlásfüggvényt pedig a `ppois(..., lambda)` függvénnyel. Az eloszlásfüggvény inverzét a `qpois(..., lambda)` függvénnyel tudjuk kiszámítani. A `?dpois` parancsot az **R**-ben lefuttatva elérjük a függvények help-jét.

Számoljuk ki mennyi az esélye, hogy ha hektáronként átlagosan 25 fa van a szavannán, akkor mennyi az esélye, hogy egy egy véletlenszerűen kiválasztott 1 hektáros parcellán pontosan 34 fa álljon!  
Mivel csak azt tudjuk, hogy átlagosan hány fa van egy hektáron, az alapfeltételezésünk az, hogy a fák a térben véletlenszerűen helyezkednek el. Ezért ezt egy $\lambda = 25$ paraméterű Poisson eloszlásból számoljuk ki. (Ugye tudjuk, hogy ennek az eloszlásnak a várható értéke és varianciája megegyezik $\lambda$-val, tehát 25!) Ezt a PMF-en úgy találjuk meg, hogy kikeressük a 34-et az x-tengelyen (piros pötty), majd leolvassuk az ehhez tartozó y-tengely értéket (kék pötty). Kézzel kiszámítva:

$$P(X=34)= e^{-25}\frac{25^{34}}{34!}$$

**R**-ben:

```{r}
dpois(34, lambda=25)
```

Számoljuk ki mennyi az esélye annak, hogy nem több mint 34 fa áll a területen ($P(X \le 34)$)! PMF: zöld oszlopok összesen, CDF: kék pötty.

```{r}
ppois(34, lambda=25)
```

Számoljuk ki, hogy hány fa van maximum egy a legkopárabb parcellák 20% -ához tartozó területen!

```{r}
qpois(0.2, lambda=25)
```


### Véletlenszerűség gyorsteszt

A Poisson eloszlás a véletlenszerűség közelítése. Tehát ha azt tapasztaljuk, hogy minták átlaga *megegyezik* a varianciájukkal, akkor sejthetjük, hogy Poisson eloszláshoz tartozik, tehát eloszlása **véletlenszerű**. De mi van akkor, ha a variancia *kisebb*, mint az átlag? Ekkor elképzeljük, hogy lehetséges ez: csakis akkor, ha az objektumok egymástól való távolságai sokkal egyformábbak, tehát ha valahogyan ezek az objektumok "tudnák" milyen messze szabad lenniük egymástól. Ez esetben az objektumok tér vagy időbeli eloszlása **szabályos**. Ha a variancia *nagyobb*, mint az átlag, akkor vannak olyan tér- vagy időrészek ahol alig találunk objektumokat és vannak olyan tér- vagy időrészek, ahol nagyon sűrűn találjuk őket. Ekkor **aggregált** eloszlásról beszélünk.

| viszony                         | variancia M(X)-hez képest \ldots | eloszlás        |
|:--------------------------------|:---------------------------------|:----------------|
| \(\displaystyle V(X) = M(X) \)  | megegyezik                       | véletlenszerű   |
| \(\displaystyle V(X) < M(X) \)  | kicsi                            | szabályos       |
| \(\displaystyle V(X) > M(X) \)  | nagy                             | aggregált       |

Ezt a biológusok gyorstesztre szokták használni, vagyis megnézik gyors, hogy hány objektumot találnak mintánként, kiszámolják ennek átlagát és varianciáját, majd megnézik a viszonyukat így gyorsan (akár terepen vagy mikroszkóp mellett) meg tudják mondani, hogy milyen eloszlású adataik vannak.  

Például tegyük fel, hogy detektálják, hogy 5 percenként hány madár látogatta meg a téli etetőt. Az adatok: 2, 1, 5, 9, 10, 4, 0, 0, 0, 1, 0, 1, 3. Kérdés: gyorsan becsüljük meg, hogy szabályosan érkeznek-e a madarak az etetőhöz.

| start | end   | bird (pieces) |
|:------|:------|---------------|
| 12:00 | 12:05 | 2             |
| 12:05 | 12:10 | 1             |
| 12:10 | 12:15 | 5             |
| 12:15 | 12:20 | 9             |
| 12:20 | 12:25 | 10            |
| 12:25 | 12:30 | 4             |
| 12:30 | 12:35 | 0             |
| 12:35 | 12:40 | 0             |
| 12:40 | 12:45 | 0             |
| 12:45 | 12:50 | 1             |
| 12:50 | 12:55 | 0             |
| 12:55 | 13:00 | 1             |
| 13:00 | 13:05 | 3             |

Kiszámoljuk a varianciát és átlagot!

```{r}
madar <- c(2, 1, 5, 9, 10, 4, 0, 0, 0, 1, 0, 1, 3)
var(madar) # variancia
mean(madar) # varhato ertek
```

Látjuk, hogy a variancia az átlaghoz képest nagy, így tippünk szerint inkább aggregáltan érkeznek a madarak.  
Sajnos néha a két érték közel van egymáshoz (pl. $M(X)=5.1$ és $V(X)=5.3$ ), így csak a mérőszemélyen múlik mit mond az adatairól. **Ez a módszer csak gyorstesztnek jó, a félév későbbi részében tanulunk majd jóval pontosabb módszereket is!**
