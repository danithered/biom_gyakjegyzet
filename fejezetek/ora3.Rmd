# Folytonos eloszlások


## Folytonos eloszlások általános jellemzése

### Mi az, hogy folytonos?

A diszkrét eloszlásokkal ellentétben a folytonos eloszlások kategóriáit nem tudjuk nevesíteni (értékkészletük határozottan nem megszámlálható!), a valvált **minden** kiválasztott két értéke között tudunk találni végtelen számú más értéket. (Mondhatjuk azt is, hogy folytonos eloszlás esetén a kategóriák "egymásba csúsznak".) Skálájukat tekintve ezek az intervallum és arányskálás változók. Szóval ezek legalább valós számok ($X \in  \mathbb{R}$). Például ide tartoznak minden - nem kategorizáltan - mért hosszúság, idő vagy térfogat adatok. Gondoljunk bele, hogy ha emberek magasságát mérjük, akkor ha van egy 177.01 cm és egy 177.02 cm magas emberünk, attól még megvan a lehetősége annak, hogy találunk egy olyan embert, aki a kettő közözzi magasságú, például 177.014 cm magas. Persze el kell fogadnunk, hogy a mérési hibahatárok miatt nem tudunk végtelen tizedesjegy pontosságig mérni, de a lényeg az, hogy tudjuk, hogy elméletben mérhetnénk addig (vagyis inkább közelíthetően mérhetünk addig).  
Ebből adódik, hogy egy folytonos eloszlás esetén az elemi előfordulás valószínűsége 0 ($P(X=x) = 0$). Például annak a valószínűsége, hogy egy véletlenszerűen kiválasztott ember magassága pontosan 177.02 cm nulla, ugyanis, ha megnéznénk egy sokkal jobb mérési módszerrel, láthatnánk, hogy ez az ember valójában 172.02000000000000000001 cm magas, csak nem tudunk addig mérni.


### Folytonos adatokkal való számolás

|x                        |n            | p        |
|:-----------------------:|:-----------:|:--------:|
| \(\displaystyle x_1 \)  | 1           | 0        |
| \(\displaystyle x_2 \)  | 1           | 0        |
| \(\displaystyle x_3 \)  | 1           | 0        |
| \(\displaystyle x_4 \)  | 1           | 0        |
| \(\displaystyle x_5 \)  | 1           | 0        |
| $\vdots$                | $\vdots$    | $\vdots$ |
| \(\displaystyle x_N \)  | 1           | 0        |


Folytonos eloszlás esetén minden megfigyelés legfeljebb csak egyszer fog előkerülni, így nincs értelme számolni az elemi előfordulások számát, sem a gyakoriságát nézni (előbbi mindig 0 vagy 1, utóbbi mindig 0).  
Ugyan azt nem lehet megmondani, hogy egy valvált **pontosan** megegyezik-e egy adott értékkel ($X ?= x$), azt meg tudjuk mondani, hogy egy adott értéknél kisebb ($X ?\le x$) vagy nagyobb-e ($X ?\ge x$). Így el tudjuk azt is dönteni, hogy bele tartozik-e egy adott intervallumba ($X ?\in [a;b]$). 
Régebben, mikor még nem állt elég számítási kapacitás rendelkezésre, a könnyebb számolás érdekében kategorizálni szokták a folytonos változókat, azaz meg szoktak húzni $\delta x$ szélességű intervallumokat és ebbe szokták belerakni a folytonos változókat (megszámolják hány vátozó esik bele az adott intervallumokba - $n$, illetve kiszámolják ezek gyakoriságát - $p$). Ezt az eljárást hívjuk "diszkretizálás"-nak. Egy ilyet mutat meg a lenti táblázat.


|x intervallum                                                  |n            | p                                                      |
|:-------------------------------------------------------------:|:-----------:|:------------------------------------------------------:|
| \(\displaystyle [x_0; x_0 + \delta x] \)                      | n_1         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + \delta x; x_0 + 2 \delta x)] \)        | n_2         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + 2 \delta x; x_0 + 3 \delta x)] \)      | n_3         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| \(\displaystyle [x_0 + 3 \delta x; x_0 + 4 \delta x)] \)      | n_4         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |
| $\vdots$                                                      | $\vdots$    | $\vdots$                                               |
| \(\displaystyle [x_0 + (m-1) \delta x; x_0 + m \delta x)] \)  | n_m         | \(\displaystyle  p_1 = {n_1} / {\sum n_i} = n_1 / N \) |

Ennél bonyolultabb, ha a $\delta x$ értékek kategóriánként eltérnek, azaz a diszkrét csoportokat más-més szélességű intervallumok alkotják. A diszkretizált adatokkal való számolást nem tanuljuk a kurzus során (mivel a XXI. században az adna releváns gyakorlati tudást), de a diszkretizálás fogalmával tisztában kell lenni.  


Fontos megkülönböztetni, hogy adatokról vagy eloszlásokról beszélünk-e! A folytonos eloszlások elméleti fogalmak, azok a valós adatoktól függetlenek! Folytonos eloszlásokkal tudjuk **jellemezni** a valós adatokat, de azok nem egyeznek meg, ne keverjük össze a fogalmakat!  

### PDF és CDF

A diszkrét eloszlásokkal ellentétben a folytonos tömegfüggvényeket nem szoktuk valószínűségi tömegfüggvénnyel (PMF) jellemezni (hisz annak értéke mindig 0 lenne), cserébe **sűrűségfüggvénnyel** (PDF = **P**robability **D**ensity **F**unction) jellemezzük. A sűrűségfüggvény a valvált értékeihez olyan értékeket rendel, ami körülbelül azt mutatja meg, hogy mekkora a relatív esélye annak, hogy a valvált adott értékéhez közeli értéket húzunk ki. (Ne felejtsük el, annak az esélye, hogy pontosan egy adott számot húzunk ki 0!) Más megközelítéssel, mekkora az esélye annak, hogy egy random minta átlaga megegyezzen a valvált adott értékével más random mintákhoz képest.  
A sűrűségfüggvény szemléletes megértésében segít, ha elképzeljük, hogy a folytonos valváltot diszkretizáljuk és megnézzünk annak PMF-ét. Ha nagy kategóriákat veszünk ($\delta x$ nagy, azaz a kategóriák száma $m$ kicsi) és összehasolítjuk az eredeti folytonos eloszlás PDF-ével, azt látjuk, hogy bár karakterisztikájában a két függvény hasonlít, azért vannak erős eltérések. Ha azonban kisebb kategóriákat veszünk ($\delta x$ kisebb, azaz a kategóriák száma $m$ nagyobb), a két függvény kezd hasonlítani egymásra. Könnyű elképzelni, hogy ahogy $\delta x$ egyre kisebb lesz, azaz tart a nullához (a valvált egyre inkább kezdi elveszteni diszkrét jellegét), a két függvény kezd egyre jobban hasonlítani egymáshoz. Azonban, míg a diszkrét függvény esetén az y-tengely a valószínűséget mutatta, a folytonos esetén a sűrűséget.  

```{r , fig.cap="Normális (folytonos) eloszlás közelítése binomiális (diszkrét) eloszlással. Az első oszlopban a piros vonalak a normális eloszlás valválthoz tartozó sűrűségfüggvényét (PDF) rajzolják ki, míg a szürke oszlopok a binomiális eloszláshoz tartozó tömegfüggvényét (PMF). A második oszlopban a normális eloszláshoz (piros vonal) és a binomiális eloszláshoz (szürke oszlopok) tartozó eloszlásfüggvények (CDF) vannak. Fentről lefelé soronként nő a binomiális eloszlás mintamérete, azaz a diszkretizálás felbontása."}
prob=0.5
size=3
plot1 <- 
	ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red") +
		labs(title="PMF/PDF" ) +
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot2 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		labs(title="CDF" ) +
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

size=4
plot3 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot4 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())


size=10
plot5 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot6 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())


size=50
plot7 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot8 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

size=150
plot9 <- ggplot(data.frame(x = 0:size, y=dbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=dnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

plot10 <- ggplot(data.frame(x = 0:size, y=pbinom(0:size, size=size, prob=prob )), aes(x,y)) +
    geom_bar(stat="identity")  +
    stat_function(fun=pnorm, args=list(mean=size*prob, sd=sqrt(size*prob*(1-prob))), col="red")+
		theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank())

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10, ncol=2)


```


Míg folytonos eloszlás esetén nincs értelme elemi valószínűségeket számolni, intervallumok valószínűségét tudjuk és érdemes kiszámolni. Ezt a sűrűségfüggvényből úgy tudjuk kiszámolni, hogy megnézzük a valvált kijelölt intervallumához tartozó függvény alatti terület nagyságát, azaz az integrálját. Az eloszlásfüggvény ($F(X)$) tehát valójában a sűrűségfüggvény ($f(X)$) integrálja.

$$F(X,x)=\int_{- \infty}^{x} f(X) =P(X \le x)$$

A sűrűségfüggvény határozott intergálja megmutatja, hogy egy véletleszerűen húzott valvált mekkora valószínűséggel vesz fel $a$ és $b$ közötti értéket.

$$\int_A^B f(X) = P(a \le X \le b)$$


Ha a valvált teljes intervallumát nézzük (mínusz végtelentől plusz végtelenig), azt tudjuk, hogy az ahhoz tartozó valószínűség 1, azaz a sűrűségfüggvény határozatlan integrálja 1. (Vagyis a sűrűségfüggvény alatti terület nagysága = 1.)

$$\int_{- \infty }^{+ \infty} f(X) = 1$$

### Valószínűségek számítása

Ha meg akarjuk nézni, hogy egy valvált mekkora valószínűséggel vesz fel egy adott $a$ értéknél kisebbet, akkor így számoljuk ki:

$$P(X \le a) =F(a) = \int_{- \infty}^{a} f(X)$$

Ne felejtsük el, hogy mivel az elemi előfordulás valószínűsége 0 ($P(X=a)=0$), ezért $P(X \le a) = P(X < a)$!

Előbbi valószínűséget a sűrűségfüggvényről úgy lehet "leolvasni", hogy x tengelyen kikeressük $a$ értékét (piros pont az ábrán) és megnézzük, hogy mekkora az $a$ pont előtt a függvény alatti (az ábrán zöld) terület nagysága. Természetesen ezt ténylegesen leolvasni nem tudjuk. A CDF-ről viszont igen, csak meg nézni, hogy a valvált adott értékéhez milyen érték tartozik az y-tengelyen (zöld pötty). 

```{r}
a=2
plot1 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")

plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= pnorm(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,pnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=pnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a"), breaks=c(0, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = pnorm(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = pnorm(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)

```

Azonban, ha arra vagyunk kíváncsiak, hogy milyen valószínűséggel vesz fel egy adott $a$ értéknél nagyobb értéket, akkor ki kell használnunk, hogy 

$$\int_{- \infty}^{+ \infty} f(X) =1$$

azaz, hogy a teljes eseménytér valószínűsége (a görbe alatti teljes terület) 1. Tehát 1-ből ha kivonjuk annak a térrésznek a nagyságát, ami az adott térrésznél kisebb (ábrán a zöld terület) - vagyis annak a valószínéségét, hogy $a$-t vagy kisebbet húzunk, akkor megkapjuk annak a valószínűségét, hogy $a$-nál nagyobbat húzunk (ábrán a görbe alatti nem színezett terület).

$$P(X \ge a) = 1-P(X \le a) = 1- \int_{- \infty}^a f(X)$$

Ha blokkokra / intervallumokra vagyunk kíváncsiak, akkor is úgy járunk el, hogy kivonjuk egymásból a valószínűségeket ("területeket"). Ha pl. arra vagyunk kíváncsiak, hogy mekkora eséllyel vesz fel egy valvált $a$ és $b$ közötti értéket először kiszámoljuk $P(X \le b)$-t (Step 1 zöld rész), majd kivonjuk belőle azt a részt, ami nem kell (Step 2 piros rész), vagyis $P(X \le a)$-t és ami marad az a végeredmény (Result zöld rész). 

```{r , echo=F, fig.height=2, fig.cap="Legalább a és legfeljebb b kiszámolása"}

a=1
b=2
plot1 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,b)
                , geom = "area"
                , fill="lightgreen"
                ) +
	#geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	#geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	#annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	#annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Step 1")

plot2 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,b)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="coral"
                ) +
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Step 2")

plot3 <- ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(a,b)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Result")



	

grid.arrange(plot1, plot2, plot3, ncol=3)
```

$$P(a \le X \le b) = P(X \le b) - P(X \le a)= \int_a^b f(X) = \int_{- \infty}^b f(X) - \int_{- \infty}^a f(X)$$
Ha annak a valószínűségét akarjuk kiszámolni, hogy egy valvált értéke **nem** esik $a$ és $b$ közé, azaz $a$-nál kisebb vagy $b$-nél nagyobb ( . ábra), az előző részben kiszámolt valószínűséget kivonjuk 1-ből.

```{r}
a=1
b=2
ggplot() +
	stat_function(fun = dnorm 
                , xlim = c(-3,a)
                , geom = "area"
                , fill="lightgreen"
                ) +
	stat_function(fun = dnorm 
                , xlim = c(b,3)
                , geom = "area"
                , fill="lightgreen"
                ) +
	#geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dnorm(c(a,a))), colour="lightblue", lwd=1.5)+
	#geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dnorm(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dnorm, xlim=c(-3,3)) +
	scale_x_continuous(labels=c(expression(mu), "a", "b"), breaks=c(0, a, b))+ 
	theme(legend.position = "none")+
	#annotate(geom = "point", x = -Inf, y = dnorm(a), size = 2, color = 'blue')+
	#annotate(geom = "point", x = a, y = dnorm(a), size = 2)+
	#annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	#coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)")
```

$$P( X \le a ~ | ~ X \ge b) = 1-P(a \le X \le b) = 1- (P(X \le b) - P(X \le a)) = 1- P(X \le b) + P(X \le a)) $$

$$\int_{-\infty}^a f(X) + \int_{b}^{+\infty} f(X) = 1- \left ( \int_{- \infty}^b f(X) - \int_{- \infty}^a f(X) \right ) = 1- \int_{- \infty}^b f(X) + \int_{- \infty}^a f(X) $$

Néha visszafelé is számolni kell: adott egy valószínűségi érték és ehhez kell kiszámolni, hogy a valvált melyik értéktartományához (intervallum alsó-, felső határának kiszámítása) tartozik. Ezt a reverz CDF-el tudjuk kiszámolni.

**R**-ben a CDF-et és a reverzét a `p...()` és `q...()` formájú függvényekkel fogjuk elérni.

$$
\begin{gathered}
valvált \rightarrow \mathbf{p} \rightarrow P(X \le x) \\
P(X \le x) \rightarrow \mathbf{q} \rightarrow valvált 
\end{gathered}
$$

## Egyenletes eloszlás

### Általános leírás

Az egyenletes eloszlás az, amikor minden érték egyforma valószínűséggel fordul elő egy adott intervallumban. Ez leggyakrabban leggyakrabban mint elméleti feltevés fordul elő.  
Az egyenletes eloszlás két paramétere a *minimum* és *maximum* érték. A sűrűségfüggvény képlete:

$$f(X) = \frac {1}{max-min} \text{, ha } a \le X \le b$$

Az eloszlásfüggvény pedig

$$F(X)=\frac{X-min}{max-min}$$

### Várható érték, variancia

Az eloszlás várható értéke a valvált minimuma és maximuma által jelzett intervallum közepe:

$$E(X)= \frac { max + min }{2}$$

Az eloszlás varianciája:

$$SD^2(X)=\frac {(max-min)^2}{12}$$



### Valószínűségek számítása


```{r unif, fig.cap="Egyenletes eloszlás PDF és CDF\\label{discrunif}", echo=FALSE}
a=0.4

plot1 <- ggplot() +
	stat_function(fun = dunif 
								, xlim = c(-1,a)
								, geom = "area"
								, fill="lightgreen"
	) +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= dunif(c(a,a))), colour="lightblue", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,dunif(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=dunif, xlim=c(-1,2)) +
	scale_x_continuous(labels=c("min", "max", "a"), breaks=c(0, 1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = dunif(a), size = 2, color = 'blue')+
	annotate(geom = "point", x = a, y = dunif(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="f(X)", title="Probability Density Function")


plot2 <- ggplot() +
	geom_step(aes(x, y), data=data.frame(	x= c(a, -Inf),	y= punif(c(a,a))), colour="lightgreen", lwd=1.5)+
	geom_step(aes(x, y), data=data.frame(	x= c(a, a),	y= c(-Inf,punif(a) )), colour="coral", lwd=1.5)+
	stat_function(fun=punif, xlim=c(-1,2)) +
	scale_x_continuous(labels=c("min", "max", "a"), breaks=c(0,1, a))+ 
	theme(legend.position = "none")+
	annotate(geom = "point", x = -Inf, y = punif(a), size = 2, color = 'green')+
	annotate(geom = "point", x = a, y = punif(a), size = 2)+
	annotate(geom = "point", x = a, y = -Inf, size = a, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="F(X)", title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=2)
```

A . ábrán látható a folytonos egyenletes eloszlás tömegfüggvénye és eloszlásfüggvénye. A PDF-en látható, hogy a minimum és maximum között egyenlő valószínűséggel húzhatunk ki számokat, míg azokon kívül nem húzhatunk ki.   

Ha ki szeretnénk számolni, hogy mennyi az esélye, hogy $a$ -nál kisebb értéket vesz fel egy random kihúzott szám, leolvashatjuk a grafikonokról: A PMF-en kikeressük az x-tengelyen $a$-t (piros pötty), majd leolvassuk mekkora a területe a görbe alatti terület azon részének, ami $a$ előtt van. Természetesen ezt a gyakorlatban nem tudjuk (és nem érdemes) megcsinálni. Szerencsére a CDF -ről le tudjuk olvasni: az $a$-hoz tartozó függvényértéket kikeressük az y-tengelyen (zöld pötty). De ki is számolhatjuk kézzel: 

$$F(a)=\frac{a-min}{max-min}$$

, vagy **R**-ben:

```{r}
min=5
max=10
a=7
punif(a, min, max)
```

Ha ugyanebből az eloszlából meg szeretnénk tudni, hogy a "nagyobbik" harmad honnan kezdődik, akkor a reverz eloszlásfügvényt használjuk.

```{r}
qunif(1-1/3, min, max)
```

Azért $1-1/3$ -ra számoltuk, mert a harmadik harmadra voltunk kíváncsiak.

## Normális eloszlás

### Általános leírás

A normális eloszlás a természetben leggyakrabban előforduló eloszlás. Ennek okairól lásd az előadás centrális határeloszlás tételről szóló részét!  
Az eloszlást valahogy úgy kell elképzelni, hogy van egy érték ($\mu$ - várható érték) ami jelöli, hogy az értékek leggyakrabban arrafelé, annak közvetlen környezetében vannak, ettől az értéktől távol meg ugyan előfordulhatnak értékek, de csak nagyon ritkán. Ez az eloszlás a várható értékére **szimmetrikus** és csak 1 csúcsa van!
Gondoljuk például az emberek magasságára! Ugyan mi látjuk a különbségeket egymás közt, de a többség körülbelül egyforma magas. Ha pedig találkozunk egy 0.5 méter vagy egy 2,3 m méter magas emberrel, akkor csodálkozunk, mert ugyan előfordulhat, de nagyon-nagyon ritkán.  

A normális eloszlás paraméterei:

* $\mu$: **várható érték** (merre várhatóak az értékek)
* $\sigma$: **szórás** (mennyire szóródottak az értékek a várható értékhez képest)

### Standard normális eloszlás


Ha több normális eloszlást össze akarunk hasonlítani, kell lennie egy alapnak, amihez minden mást viszonyítunk. Ez lesz a standard. Definíció szerint a standard normális eloszlás várható értéke 0 ($\mu=0$), szórása 1 ($\sigma=1$). Sok más eloszlásnak, így sok statisztikai módszernek/próbának ez lesz az alapja, így érdemes az eloszlás főbb jellegzetességeit eszünkbe vésni!

A standard normális eloszlás képletét akár magunknak is levezethetjük. Először is vegyük a főbb jellegzetességeket: 0-ra szimmetrikus, valahogyan "görbülő" függvény. Erre a legegyszerűbb pélfa a négyzet függvény:

$$f(x) = x^2$$
```{r}
curve(x^2, xlim=c(-2,2))
```

Ezt azonban meg kéne fordítani...


$$f(x) = -x^2$$

```{r}
curve(-x^2, xlim=c(-2,2))
```

Máris jobb, azonban a görbülete nem jó - nekünk konkáv függvény kellene, ráadásul negatív az egész. A legegyszerűbb függvény, ami az előző két feltételt teljesíti, az a az exponenciális függvény ($e^x$). Emeljük az előző függvényünket exponenciálisra!

$$f(x) = e^{-x^2}$$

```{r}
curve(exp(-x^2), xlim=c(-2,2))
```

Máris sokkal jobb! Már csak pár probléma van:



















Annak a valószínűségét, hogy $k$ db megfelelő objektumot veszünk ki a mintából, a következőképpen számolhatjuk ki:  
Először is vegyük azt, hogy mennyi az esélye, hogy egy random kihúzott objektum megfelelő - ez ugye $p$. Mivel függetlenek egymástól az elemi események, ezért annak a valószínűsége, hogy 2 kihúzott objektumból 2 megfelelő $p *p=p^2$, annak a valószínűsége pedig, hogy $k$ kihúzott objektumból $k$ megfelelő $p^k$. Ezt megszorozzuk azzal, hogy hányféleképpen lehet az $n$ nagyságú mintából $k$ objektumot kiválogatni, ami ugye $n \choose k$. Ezzel még nem végeztünk, mert számolni kell azzal, hogy a minta maradékának ($n-k$) a másik típusból kell lennie. Annak a valószínűsége, hogy egy random objektum a másik típusú lesz $1-p$. Így annak a valószínűsége, hogy $n-k$ objektum a másik típusú lesz $(1-p)^{n-k}$. A képlet összerakva:

$$P(X=k) = {n \choose k} p^k (1-p)^{n-k}$$

### Várható érték, variancia

Az eloszlás várható értéke a minta elemszáma szorozva a megfelelő objektumok gyakoriságával 

$$E(X)= np$$

Az eloszlás varianciája:

$$SD^2(X)= np(1-p)$$

Számoljuk ki egy binomiális eloszlás várható értékét és szórását! Tegyük fel, hogy van egy génváltozat ami az emberi populáció 2/5-ében megtalálható. Számítsuk ki annak az eloszlásnak a várható értékét és szórását ami azt mutatja meg hány emberben van meg ez a génváltozat, ha 40 véletlenszerűen kiválasztott emberből álló mintát veszünk!

Az eloszlásra specifikus képletekkel:

```{r}
n = 40
p = 0.4

n*p # varhato ertek

n*p*(1-p) # variancia
sqrt(n*p*(1-p)) # szoras
```

Általános képletekkel:

```{r}
x <- 0:40 # ennyi ember tartalmazza lehetsegesen a gent
p <- dbinom(x, size = n, prob = 0.4) #kategoriak gyakorisaga
```

A fenti függvény (`dbinom(x, size = n, prob = 0.4)`) az $x$-hez tartozó valószínűségeket számolta ki. Erről bővebben a következő alfejezetben lesz szó.  
Mivel így már ismertek a válvált lehetséges értékei és azok valószínűsége, a várható érték és a variancia kiszámítása általános képletekkel:

```{r}
sum(p*x) #varhato ertek
sum(p*x^2) - sum(p*x)^2 #variancia
sqrt(sum(p*x^2) - sum(p*x)^2) #szoras
```

### Valószínűségek számítása


```{r binom, echo=FALSE, fig.cap="Binomiális eloszlás PMF és CDF. Az eloszlás paraméterei: *n* = 40, *p* = 0.4 \\label{bino}"}

plot1 <- ggplot(data.frame(x=0:40,
									y=dbinom(0:40, size=40, prob=0.4), 
									col=as.character(c(rep("green",15),rep("grey",26))))) +
	geom_step(aes(x, y), data=data.frame(	x= c(14, -Inf),	y= dbinom(c(14,14),size=40, prob=0.4)), colour="lightblue", lwd=1.5)+
  #geom_bar(aes(y = ..prop.., fill=col)) +
	geom_bar(aes(x=x,y=y,fill=col), stat="identity") +
	#xlim(0,15)+
	#scale_x_discrete(labels=c("5"="min", "7"="x", "10"="max"))
	scale_x_continuous(labels=c("0", "a", "M", "n"), breaks=c(0, 14 , 0.4*40,40))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "grey40"))+
	annotate(geom = "point", x = -Inf, y = dbinom(14,size=40, prob=0.4), size = 2, color = 'blue')+
	annotate(geom = "point", x = 14, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y="P(X)", title="Probability Mass Function")


plot2 <- ggplot(data.frame(x=0:40,y=pbinom(0:40, size=40, prob=0.4)) )+
	geom_step(aes(x, y), data=data.frame(	x= c(14, -Inf),	y= pbinom(c(14,14),size=40, prob=0.4)), colour="lightgreen", lwd=1.5)+
	geom_bar(aes(x=x, y=y), stat="identity")+
	scale_x_continuous(labels=c("0", "a", "M", "n"), breaks=c(0, 14 , 0.4*40,40))+ 
	theme(legend.position = "none")+
	scale_fill_manual("", values = c("green" = "lightgreen", "grey" = "darkgrey"))+
	annotate(geom = "point", x = -Inf, y = pbinom(14,size=40, prob=0.4), size = 2, color = 'green4')+
	annotate(geom = "point", x = 14, y = -Inf, size = 2, color = 'red')+
	coord_cartesian(clip = 'off')+
	labs(x="X", y=expression(P(X <= x) ), title="Cumulative Density Function")


grid.arrange(plot1, plot2, ncol=1)
```

A . ábrán látható a binomiális eloszlás tömegfüggvénye és eloszlásfüggvénye.  
Ezeket **R**-ben vagy a fenti képlettel, vagy specifikus függvényekkel tudjuk kiszámolni. A tömegfüggvényt a `dbinom(..., size, prob)` függvénnyel, az eloszlásfüggvényt pedig a `pbinom(..., size, prob)` függvénnyel, ahol a `size` a mintaméret, azaz $n$, a `prob` pedig az elemi esemény valószínűsége, tehát $p$. Az eloszlásfüggvény inverzét a `qbinom(..., size, prob)` függvénnyel tudjuk kiszámítani. Ha elfelejtenénk, hogy a függvény paraméterei mit jelentenek futtassuk le a `?dbinom` parancsot az **R**-ben és a helpből kikereshetjük.


Számoljuk ki mennyi az esélye, hogy nem pontosan 14 ember ember tartalmazza ezt gént! Ezt úgy lehet legegyszerűbben kiszámolni, hogy az 1-ből kivonjuk annak a valószínűségét, hogy 14 ember (PMF: piros pont) tartalmazza a gént (PMF: kék pont).

$$P(nem ~ 14)=1-P(X=14)= 1- {40 \choose 14} 0.4^{14} (1-0.4)^{40-14}$$

**R**-ben:

```{r}
1 - dbinom(14, size=40, prob=0.4)
```


